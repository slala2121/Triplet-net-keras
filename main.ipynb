{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slala2121/Triplet-net-keras/blob/COS597D/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSyNevUSxe-e",
        "colab_type": "code",
        "outputId": "51974019-fdf3-46cf-c7a0-62522bc6ab40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (42.0.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (1.10.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.2.7)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shb7vg6Q_SkV",
        "colab_type": "code",
        "outputId": "4f659ef0-347d-457f-865b-44abe1ff79d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51i3YfyuAaGO",
        "colab_type": "code",
        "outputId": "06f23cbd-b053-46db-a06b-0b6ce15480cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from itertools import permutations\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import scipy.io\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.optimizers as optimizers\n",
        "from tensorflow.keras.preprocessing import image\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb06WTrH_rHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_source_dir='/content/drive/My Drive/COS597D_proj/data/animal'\n",
        "source_path=os.path.join('drive','My Drive', 'Colab Notebooks')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfECMevi_53q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load human similarity judgment data\n",
        "\n",
        "human_sim_data=scipy.io.loadmat(os.path.join(data_source_dir,'turkResults_CogSci2016.mat'))\n",
        "\n",
        "data_order=human_sim_data['animals_big_idx']\n",
        "human_sim_scores=human_sim_data['simMatrix']\n",
        "human_sim_scores_normalized=human_sim_scores*1.0/np.amax(human_sim_scores)\n",
        "\n",
        "# flattens the vector\n",
        "human_sim_scores_tril=human_sim_scores[np.tril_indices(120,k=-1)]\n",
        "human_sim_scores_normalized_tril=human_sim_scores_normalized[np.tril_indices(120,k=-1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCDtohvQA1SJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load corresponding images\n",
        "images_ordered=sorted(os.listdir(os.path.join(data_source_dir,'images')))\n",
        "num_images=len(images_ordered)\n",
        "\n",
        "# this order corresponds to the order prescribed in data_order"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-eKq5sKRbjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "\n",
        "# based on the lifted scheme paper\n",
        "def create_deep_base_network(input_dim,loss_type,num_classes=0,transfer=False,freeze_weights=False):\n",
        "  weights='imagenet' if transfer else None\n",
        "  conv_base = ResNet50(weights=weights, include_top=False, input_shape=input_dim)\n",
        "\n",
        "  if freeze_weights:\n",
        "    for layer in conv_base.layers:\n",
        "      layer.trainable=False\n",
        "  \n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Input(input_dim))\n",
        "  model.add(conv_base)\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.BatchNormalization())\n",
        "\n",
        "  if loss_type=='classification':\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "  else:\n",
        "    model.add(layers.Dense(64, activation=None))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def create_shallow_network(input_dim,loss_type,num_classes=0):\n",
        "  model=tf.keras.Sequential()\n",
        "  model.add(layers.Input(input_dim))\n",
        "  model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=5, padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=2, padding='same'))\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  if loss_type=='classification':\n",
        "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers(Dense(num_classes,activation='softmax')))\n",
        "  else:\n",
        "    model.add(tf.keras.layers.Dense(256, activation=None))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "  return model\n",
        "\n",
        "def construct_model(model_type,input_dim,loss_type,num_classes,transfer=False,freeze_weights=False):\n",
        "  if model_type=='shallow':\n",
        "    model=create_shallow_network(input_dim,loss_type,num_classes)\n",
        "  elif model_type=='deep':\n",
        "    model=create_deep_base_network(input_dim,loss_type,num_classes,transfer,freeze_weights)\n",
        "\n",
        "  if loss_type =='triplet':\n",
        "    model.add(tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)))\n",
        "  return model\n",
        "\n",
        "def construct_loss(loss_type,margin):\n",
        "  if loss_type=='triplet':\n",
        "    loss=tfa.losses.TripletSemiHardLoss(margin=margin)\n",
        "  elif loss_type=='lifted':\n",
        "    loss=tfa.losses.LiftedStructLoss(margin=margin)\n",
        "  elif loss_type=='classification':\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy()\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0hxjtqz4KKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_type='deep'\n",
        "dataset_name='cifar10'\n",
        "input_dim=(32,32,3)\n",
        "train_mean=np.load(os.path.join(source_path,dataset_name,'train_mean.npy'))\n",
        "loss_type='lifted'\n",
        "num_classes=10\n",
        "transfer=True\n",
        "freeze_weights=False\n",
        "margin=1.0\n",
        "\n",
        "def preprocess_input(img):\n",
        "  \n",
        "  preprocessed_img=img.copy()\n",
        "  preprocessed_img=preprocessed_img.astype('float32')\n",
        "  preprocessed_img=preprocessed_img-train_mean\n",
        "  preprocessed_img=preprocessed_img/255.\n",
        "\n",
        "  return preprocessed_img\n",
        "\n",
        "model=construct_model(model_type,input_dim,loss_type,num_classes)\n",
        "filepath=os.path.join('final_%s_%s_transfer_%s_freeze_%s_margin_%s.h5'%(loss_type,model_type,transfer,freeze_weights,margin))\n",
        "# filepath='final_classification_deep_transfer_True_freeze_False_margin_1.0.h5'\n",
        "model_file_path=os.path.join(source_path,dataset_name,model_type,filepath)\n",
        "model.load_weights(model_file_path)\n",
        "embeddings_layer=model.layers[-2]\n",
        "embeddings_layer_model=tf.keras.models.Model(model.input,embeddings_layer.output)\n",
        "# model = tf.keras.models.load_model(model_file_path) # bug with metric learning\n",
        "\n",
        "# baseline VGG-19\n",
        "# model=tf.keras.applications.VGG19(weights='imagenet',include_top=True)\n",
        "# embeddings_layer_model = models.Model(inputs=model.input, outputs=model.layers[-2].output)\n",
        "# input_dim=(224,224,3)\n",
        "# preprocess_input=tf.keras.applications.vgg19.preprocess_input\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkKW-8Cga_An",
        "colab_type": "code",
        "outputId": "5e1d9074-3af9-4632-af14-32b8f6cceaa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 1, 1, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 2048)              8192      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                131136    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "=================================================================\n",
            "Total params: 23,727,040\n",
            "Trainable params: 23,669,824\n",
            "Non-trainable params: 57,216\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMwHAbsPl9Ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image preprocess and compute the activations\n",
        "\n",
        "# compute activations from penultimate layer from a classification network \n",
        "\n",
        "# compute image features in order of the images\n",
        "images_features=[]\n",
        "for image_fname in images_ordered:\n",
        "  img = image.load_img(os.path.join(data_source_dir,'images',image_fname), target_size=input_dim)\n",
        "  x = image.img_to_array(img)\n",
        "  x = preprocess_input(x)\n",
        "  x = np.expand_dims(x, axis=0) # reshape in batch format\n",
        "\n",
        "  features = embeddings_layer_model.predict(x)[0]\n",
        "  images_features.append(features)\n",
        "\n",
        "images_features=np.array(images_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIK08tnjsiyC",
        "colab_type": "code",
        "outputId": "e32eae70-0aa9-430c-8169-a54acc572c1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# compute correlations bet. DNN feature similarities and human similarity scores\n",
        "\n",
        "nn_sim_scores=cosine_similarity(images_features,images_features)\n",
        "nn_sim_scores_tril=nn_sim_scores[np.tril_indices(120,k=-1)]\n",
        "\n",
        "nn_sim_scores_normalized=nn_sim_scores*1.0/np.amax(nn_sim_scores)\n",
        "nn_sim_scores_normalized_tril=nn_sim_scores_normalized[np.tril_indices(120,k=-1)]\n",
        "\n",
        "\n",
        "np.corrcoef(human_sim_scores_normalized_tril,nn_sim_scores_normalized_tril)**2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.00152039],\n",
              "       [0.00152039, 1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1C3q-U5KK8N",
        "colab_type": "code",
        "outputId": "842b3aa9-a167-4ed1-c3d3-afe974de8a1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# run MDS\n",
        "\n",
        "from sklearn import manifold\n",
        "import time\n",
        "\n",
        "mds = manifold.MDS(n_components=2, metric=True, max_iter=10000, eps=1e-100,\n",
        "                    dissimilarity=\"precomputed\")\n",
        "mds_human_sim_embed_coords=nmds.fit_transform(human_sim_scores_normalized)\n",
        "nmds = manifold.MDS(n_components=2, metric=False, max_iter=10000, eps=1e-100)\n",
        "nmds_human_sim_embed_coords=nmds.fit_transform(mds_human_sim_embed_coords)\n",
        "\n",
        "# visualize NMDS\n",
        "\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "\n",
        "\n",
        "fig,ax=plt.subplots(figsize=(5,5))\n",
        "\n",
        "for image_index,image_fname in enumerate(images_ordered):\n",
        "  img = image.load_img(os.path.join(data_source_dir,'images',image_fname), target_size=(224, 224))\n",
        "  img = image.img_to_array(img)\n",
        "  img*=1.0/np.amax(img)\n",
        "\n",
        "  im = OffsetImage(img, zoom=0.1)\n",
        "  im_nmds_coords=(nmds_human_sim_embed_coords[image_index][0],\n",
        "                  nmds_human_sim_embed_coords[image_index][1])\n",
        "  ab = AnnotationBbox(im, im_nmds_coords,frameon=False)\n",
        "  ax.add_artist(ab)\n",
        "\n",
        "ax.autoscale()\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(120, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sliwKHx6P69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}