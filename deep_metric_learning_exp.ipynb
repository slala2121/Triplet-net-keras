{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_metric_learning_exp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slala2121/Triplet-net-keras/blob/COS597D/deep_metric_learning_exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaNjSYSpsPV4",
        "colab_type": "text"
      },
      "source": [
        "Code adapted from:\n",
        "https://github.com/KinWaiCheuk/Triplet-net-keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41Rx-qWmmlTw",
        "colab_type": "text"
      },
      "source": [
        "Other relevant links:\n",
        "\n",
        "scratch classification network from https://keras.io/examples/cifar10_resnet/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILvdYoh4ikGN",
        "colab_type": "code",
        "outputId": "b315f269-491a-4dc6-88b3-3cb5979dca80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dOIE44amJSk",
        "colab_type": "code",
        "outputId": "1aa82a5e-0d5c-4285-abf1-4f1825db166e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install --upgrade tensorflow\n",
        "!pip install tensorflow-addons\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 37kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.4)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 56.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 38.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (42.0.2)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.16.0)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/f8/84b5771faec3eba9fe0c91c8c5896364a8ba08852c0dea5ad2025026dd95/google_auth-1.10.0-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.2.7)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.8)\n",
            "\u001b[31mERROR: tensorboard 2.0.2 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.10.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-auth, tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed google-auth-1.10.0 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/b0/6a1dacc2f4fab422926bfcbab6fa8f08f2a0309d872f3b059340a409b194/tensorflow_addons-0.6.0-cp36-cp36m-manylinux2010_x86_64.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons) (1.12.0)\n",
            "Collecting tensorflow-gpu==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n",
            "\u001b[K     |████████████████████████████████| 380.8MB 44kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.1.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.17.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (3.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (3.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (2.0.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.33.6)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (2.0.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.8.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.11.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0->tensorflow-addons) (42.0.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (1.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (3.1.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (2.21.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0->tensorflow-addons) (2.8.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (4.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (0.2.7)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (1.3.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (3.0.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (3.1.0)\n",
            "Installing collected packages: tensorflow-gpu, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.6.0 tensorflow-gpu-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhYHleWkrVQ9",
        "colab_type": "code",
        "outputId": "dd30dab7-d112-449d-8547-c6ca829f2c9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# current work around for fixing the lifted structure loss file\n",
        "\n",
        "%%writefile /usr/local/lib/python3.6/dist-packages/tensorflow_addons/losses/lifted.py\n",
        "\n",
        "\n",
        "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Implements lifted_struct_loss.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow_addons.losses import metric_learning\n",
        "from tensorflow_addons.utils import keras_utils\n",
        "\n",
        "\n",
        "@keras_utils.register_keras_custom_object\n",
        "@tf.function\n",
        "def lifted_struct_loss(labels, embeddings, margin=1.0):\n",
        "    \"\"\"Computes the lifted structured loss.\n",
        "\n",
        "    Args:\n",
        "      labels: 1-D tf.int32 `Tensor` with shape [batch_size] of\n",
        "        multiclass integer labels.\n",
        "      embeddings: 2-D float `Tensor` of embedding vectors. Embeddings should\n",
        "        not be l2 normalized.\n",
        "      margin: Float, margin term in the loss definition.\n",
        "\n",
        "    Returns:\n",
        "      lifted_loss: tf.float32 scalar.\n",
        "    \"\"\"\n",
        "    # Reshape [batch_size] label tensor to a [batch_size, 1] label tensor.\n",
        "    lshape = tf.shape(labels)\n",
        "    # assert lshape.shape == 1\n",
        "    labels = tf.reshape(labels, [lshape[0], 1])\n",
        "\n",
        "    # Build pairwise squared distance matrix.\n",
        "    pairwise_distances = metric_learning.pairwise_distance(embeddings)\n",
        "\n",
        "    # Build pairwise binary adjacency matrix.\n",
        "    adjacency = tf.math.equal(labels, tf.transpose(labels))\n",
        "    # Invert so we can select negatives only.\n",
        "    adjacency_not = tf.math.logical_not(adjacency)\n",
        "\n",
        "    batch_size = tf.size(labels)\n",
        "\n",
        "    diff = margin - pairwise_distances\n",
        "    mask = tf.cast(adjacency_not, dtype=tf.dtypes.float32)\n",
        "    # Safe maximum: Temporarily shift negative distances\n",
        "    #   above zero before taking max.\n",
        "    #     this is to take the max only among negatives.\n",
        "    row_minimums = tf.math.reduce_min(diff, 1, keepdims=True)\n",
        "    row_negative_maximums = tf.math.reduce_max(\n",
        "        tf.math.multiply(diff - row_minimums, mask), 1,\n",
        "        keepdims=True) + row_minimums\n",
        "\n",
        "    # Compute the loss.\n",
        "    # Keep track of matrix of maximums where M_ij = max(m_i, m_j)\n",
        "    #   where m_i is the max of alpha - negative D_i's.\n",
        "    # This matches the Caffe loss layer implementation at:\n",
        "    #   https://github.com/rksltnl/Caffe-Deep-Metric-Learning-CVPR16/blob/0efd7544a9846f58df923c8b992198ba5c355454/src/caffe/layers/lifted_struct_similarity_softmax_layer.cpp  # pylint: disable=line-too-long\n",
        "\n",
        "    max_elements = tf.math.maximum(row_negative_maximums,\n",
        "                                   tf.transpose(row_negative_maximums))\n",
        "    diff_tiled = tf.tile(diff, [batch_size, 1])\n",
        "    mask_tiled = tf.tile(mask, [batch_size, 1])\n",
        "    max_elements_vect = tf.reshape(tf.transpose(max_elements), [-1, 1])\n",
        "\n",
        "    loss_exp_left = tf.reshape(\n",
        "        tf.math.reduce_sum(\n",
        "            tf.math.multiply(\n",
        "                tf.math.exp(diff_tiled - max_elements_vect), mask_tiled),\n",
        "            1,\n",
        "            keepdims=True), [batch_size, batch_size])\n",
        "\n",
        "    loss_mat = max_elements + tf.math.log(loss_exp_left +\n",
        "                                          tf.transpose(loss_exp_left))\n",
        "    # Add the positive distance.\n",
        "    loss_mat += pairwise_distances\n",
        "\n",
        "    mask_positives = tf.cast(\n",
        "        adjacency, dtype=tf.dtypes.float32) - tf.linalg.diag(\n",
        "            tf.ones([batch_size]))\n",
        "\n",
        "    # *0.5 for upper triangular, and another *0.5 for 1/2 factor for loss^2.\n",
        "    num_positives = tf.math.reduce_sum(mask_positives) / 2.0\n",
        "\n",
        "    lifted_loss = tf.math.truediv(\n",
        "        0.25 * tf.math.reduce_sum(\n",
        "            tf.math.square(\n",
        "                tf.math.maximum(\n",
        "                    tf.math.multiply(loss_mat, mask_positives), 0.0))),\n",
        "        num_positives)\n",
        "    return lifted_loss\n",
        "\n",
        "\n",
        "@keras_utils.register_keras_custom_object\n",
        "class LiftedStructLoss(tf.keras.losses.Loss):\n",
        "    \"\"\"Computes the lifted structured loss.\n",
        "\n",
        "    The loss encourages the positive distances (between a pair of embeddings\n",
        "    with the same labels) to be smaller than any negative distances (between\n",
        "    a pair of embeddings with different labels) in the mini-batch in a way\n",
        "    that is differentiable with respect to the embedding vectors.\n",
        "    See: https://arxiv.org/abs/1511.06452.\n",
        "\n",
        "    Args:\n",
        "      margin: Float, margin term in the loss definition.\n",
        "      name: Optional name for the op.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, margin=1.0, name=None):\n",
        "        super(LiftedStructLoss, self).__init__(\n",
        "            name=name, reduction=tf.keras.losses.Reduction.NONE)\n",
        "        self.margin = margin\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        return lifted_struct_loss(y_true, y_pred, self.margin)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            \"margin\": self.margin,\n",
        "        }\n",
        "        base_config = super(LiftedStructLoss, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /usr/local/lib/python3.6/dist-packages/tensorflow_addons/losses/lifted.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JErGQrxEs22B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u6gowOIiuxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from itertools import permutations\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.optimizers as optimizers\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "\n",
        "source_path=os.path.join('drive','My Drive', 'Colab Notebooks')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "forZgD_0iJQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare dataset either for classification or deep metric learning\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "dataset_name='cifar10'\n",
        "\n",
        "loss_type='lifted'\n",
        "DATA_AUGMENTATIONS=True\n",
        "BATCH_SIZE=32\n",
        "\n",
        "\n",
        "dataset_dir=os.path.join(source_path,dataset_name)\n",
        "if not os.path.isdir(dataset_dir):\n",
        "  os.mkdir(dataset_dir)\n",
        "\n",
        "debug=0\n",
        "\n",
        "if debug:\n",
        "  split_percent=5\n",
        "  train_split = tfds.Split.TRAIN.subsplit(tfds.percent[:split_percent])\n",
        "  test_split = tfds.Split.TEST.subsplit(tfds.percent[:split_percent])\n",
        "  train_dataset,info = tfds.load(name=dataset_name, split=train_split, as_supervised=True, with_info=True)\n",
        "  test_dataset,info = tfds.load(name=dataset_name, split=test_split, as_supervised=True, with_info=True)\n",
        "else:\n",
        "  train_dataset,info = tfds.load(name=dataset_name, split='train', as_supervised=True, with_info=True)\n",
        "  test_dataset,info = tfds.load(name=dataset_name, split='test', as_supervised=True, with_info=True)\n",
        "\n",
        "input_dim=info.features['image'].shape\n",
        "num_classes=info.features['label'].num_classes\n",
        "num_train_images=info.splits['train'].num_examples\n",
        "num_test_images=info.splits['test'].num_examples\n",
        "\n",
        "train_mean_path=os.path.join(dataset_dir,'train_mean.npy')\n",
        "if os.path.exists(train_mean_path):\n",
        "  train_mean=np.load(train_mean_path)\n",
        "else:\n",
        "  train_mean=[]\n",
        "  train_mean=[]\n",
        "  for example in train_dataset.take(num_train_images):\n",
        "    image,label=example[0],example[1]\n",
        "    image=image.numpy().astype('float32')\n",
        "    if len(train_mean)==0:\n",
        "      train_mean=image\n",
        "    else:\n",
        "      train_mean = train_mean+image\n",
        "\n",
        "  train_mean=train_mean*1.0/num_train_images\n",
        "  np.save(train_mean_path,train_mean)\n",
        "\n",
        "# separating the dataset based on classes\n",
        "combined_dataset=train_dataset.concatenate(test_dataset)\n",
        "train_classes=np.arange(num_classes/2)\n",
        "train_dataset=combined_dataset.filter(lambda image,label: label < int(num_classes/2))\n",
        "test_classes=np.arange(num_classes/2,num_classes)\n",
        "test_dataset=combined_dataset.filter(lambda image,label: label >= int(num_classes/2))\n",
        "\n",
        "\n",
        "\n",
        "# preprocessing of labels for classification\n",
        "\n",
        "def _encode_one_hot(img, label):\n",
        "    label = tf.one_hot(label,num_classes)\n",
        "    return (img, label)\n",
        "\n",
        "\n",
        "# Build your input pipelines\n",
        "# preprocessing\n",
        "\n",
        "\n",
        "if loss_type=='classification':\n",
        "  train_dataset = train_dataset.map(_encode_one_hot)\n",
        "  test_dataset = test_dataset.map(_encode_one_hot)\n",
        "\n",
        "\n",
        "train_dataset=train_dataset.map(\n",
        "    lambda image,label: (image-train_mean,label)\n",
        ").map(\n",
        "    lambda image, label: (tf.image.convert_image_dtype(image, tf.float32), label)\n",
        ")\n",
        "\n",
        "test_dataset=test_dataset.map(\n",
        "      lambda image,label: (image-train_mean,label)\n",
        ").map(\n",
        "      lambda image, label: (tf.image.convert_image_dtype(image, tf.float32), label)\n",
        ")\n",
        "\n",
        "\n",
        "if DATA_AUGMENTATIONS:\n",
        "  train_dataset=train_dataset.map(\n",
        "      lambda image, label: (tf.image.random_flip_left_right(image), label)\n",
        "  )\n",
        "\n",
        "new_input_dim=(32,32,3)\n",
        "train_dataset=train_dataset.shuffle(100).batch(BATCH_SIZE)\n",
        "test_dataset=test_dataset.batch(BATCH_SIZE)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZHsKIhMF0wU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare dataset either for classification or deep metric learning\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "dataset_name='caltech_birds2011'\n",
        "\n",
        "loss_type='lifted'\n",
        "DATA_AUGMENTATIONS=True\n",
        "BATCH_SIZE=32\n",
        "\n",
        "debug=1\n",
        "\n",
        "dataset_dir=os.path.join(source_path,dataset_name)\n",
        "if not os.path.isdir(dataset_dir):\n",
        "  os.mkdir(dataset_dir)\n",
        "\n",
        "train_dataset,info = tfds.load(name=dataset_name, split='train',as_supervised=True, with_info=True)\n",
        "test_dataset,info = tfds.load(name=dataset_name, split='test', as_supervised=True, with_info=True)\n",
        "\n",
        "input_dim=info.features['image'].shape\n",
        "num_classes=info.features['label'].num_classes\n",
        "num_train_images=info.splits['train'].num_examples\n",
        "\n",
        "# preprocessing of labels for classification\n",
        "\n",
        "def _encode_one_hot(img, label):\n",
        "    label = tf.one_hot(label,num_classes)\n",
        "    return (img, label)\n",
        "\n",
        "\n",
        "# Build your input pipelines\n",
        "# preprocessing\n",
        "\n",
        "\n",
        "if loss_type=='classification':\n",
        "  train_dataset = train_dataset.map(_encode_one_hot)\n",
        "  test_dataset = test_dataset.map(_encode_one_hot)\n",
        "\n",
        "# resize the data to compute the mean on the original training set\n",
        "train_dataset=train_dataset.map(\n",
        "    lambda image,label: (tf.image.resize(image, [256, 256]),label)\n",
        ")\n",
        "\n",
        "test_dataset=test_dataset.map(\n",
        "    lambda image,label: (tf.image.resize(image, [256, 256]),label)\n",
        ")\n",
        "\n",
        "train_mean_path=os.path.join(dataset_dir,'train_mean.npy')\n",
        "if os.path.exists(train_mean_path):\n",
        "  train_mean=np.load(train_mean_path)\n",
        "else:\n",
        "  train_mean=[]\n",
        "  train_mean=[]\n",
        "  for example in train_dataset.take(num_train_images):\n",
        "    image,label=example[0],example[1]\n",
        "    image=image.numpy().astype('float32')\n",
        "    if len(train_mean)==0:\n",
        "      train_mean=image\n",
        "    else:\n",
        "      train_mean = train_mean+image\n",
        "\n",
        "  train_mean=train_mean*1.0/num_train_images\n",
        "  np.save(train_mean_path,train_mean)\n",
        "\n",
        "# separating the dataset based on classes\n",
        "combined_dataset=train_dataset.concatenate(test_dataset)\n",
        "train_classes=np.arange(100)\n",
        "train_dataset=combined_dataset.filter(lambda image,label: label < 100)\n",
        "test_classes=np.arange(100,200)\n",
        "test_dataset=combined_dataset.filter(lambda image,label: label >= 100)\n",
        "\n",
        "if debug:\n",
        "  train_dataset=train_dataset.take(500)\n",
        "  test_dataset=test_dataset.take(100)\n",
        "\n",
        "train_dataset=train_dataset.map(\n",
        "    lambda image, label: (image-train_mean,label)\n",
        ").map(\n",
        "    lambda image, label: (tf.image.convert_image_dtype(image, tf.float32), label)\n",
        ")\n",
        "\n",
        "test_dataset=test_dataset.map(\n",
        "    lambda image, label: (image-train_mean,label)\n",
        ").map(\n",
        "      lambda image, label: (tf.image.convert_image_dtype(image, tf.float32), label)\n",
        ")\n",
        "\n",
        "\n",
        "if DATA_AUGMENTATIONS:\n",
        "  new_input_dim=(227,227,3)\n",
        "  CROP_SIZE=tf.convert_to_tensor(list(new_input_dim)) \n",
        "  train_dataset=train_dataset.map(\n",
        "      lambda image, label: (tf.image.random_flip_left_right(image), label)\n",
        "  ).map(\n",
        "      lambda image, label: (tf.image.random_crop(image,CROP_SIZE), label)\n",
        "  )\n",
        "\n",
        "  test_dataset=test_dataset.map(\n",
        "      lambda image,label: (tf.image.random_crop(image,CROP_SIZE), label)\n",
        "  )\n",
        "\n",
        "train_dataset=train_dataset.shuffle(100).batch(BATCH_SIZE)\n",
        "test_dataset=test_dataset.shuffle(100).batch(BATCH_SIZE)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ed4cf908-229e-48ec-f7a9-2bf731744599",
        "id": "203WSdOnF3XS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        }
      },
      "source": [
        "image,label=next(iter(train_dataset))\n",
        "# print(label)\n",
        "plt.figure()\n",
        "plt.imshow(image[0])\n",
        "\n",
        "image,label=next(iter(test_dataset))\n",
        "# print(label)\n",
        "plt.figure()\n",
        "plt.imshow(image[0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([4 3 3 3 4 1 3 0 0 3 2 0 1 2 0 4 4 3 0 1 4 4 2 2 1 2 2 3 0 1 0 4], shape=(32,), dtype=int64)\n",
            "tf.Tensor([9 7 9 6 9 7 5 9 6 9 8 6 8 5 6 8 7 5 5 7 5 9 6 6 5 6 6 8 5 5 8 9], shape=(32,), dtype=int64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbf9e048b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAcn0lEQVR4nO2dW4yd13Xf/+tc50YOL0NSNCmJEkVb\nUVVFlhlZQVzDTZpUcVPIRgvDfjD0YIRBEQM1kD4ILlC7QB+corbhh8IBXQuRC8e2akmwmgqJFcGo\na7iRRakUL6JEShSvpoacITkz5My5rz6cw4AS9n/NcC5naO//DyB4Zq/Z37fO/r51zpn9P2stc3cI\nIX79Kay2A0KI/qBgFyITFOxCZIKCXYhMULALkQkKdiEyobSUyWb2MIBvACgC+G/u/pXo98fGxvy2\nHTvSxwKXAG0R6qAExRvBuGUxiw+AKbrR0bgXgFlgXYR87OHZ4pnLzWI8cTLp5ImTmJiYSFoXHexm\nVgTwXwH8PoAzAF4ys2fd/TU257YdO/Czl15M2gqdDj1XmT2zAAX7jRAFO78u0Sp3yDVrBYFZMP5B\nsxQGe+Rjet6vQrBHHraJ8aEPf5jOWcrH+AcBvOnux929AeD7AB5ZwvGEECvIUoJ9G4DT1/18pjcm\nhLgJWfENOjPbY2b7zGzfxIULK306IQRhKcF+FsCt1/28vTf2Ltx9r7vvdvfdY5s2LeF0QoilsJRg\nfwnALjO7w8wqAD4N4NnlcUsIsdwsejfe3Vtm9nkAf4uu9Pa4ux+O5hiACnl98WA3nu1Khvuii91s\nzRK+kqGqFdkK6et88eJlOuXwkdep7cEP3U9ta4aGqK3TTt9Xi5UUVwLqyWJcDOYsSWd39+cAPLeU\nYwgh+oO+QSdEJijYhcgEBbsQmaBgFyITFOxCZMKSduNvFENXo0vhQRLEolQ0SW/LQyDlRMpQkUhv\nP/k/P6dzfvgM/5rGqVP/jNr+1Sf+JbWNDA0mxwto0zmx4tXHGys4VYHYouxAvbMLkQkKdiEyQcEu\nRCYo2IXIBAW7EJnQ1934CI+SMaKSRMtOdK6bJ3miX0TtwaIyUufGJ5PjTz3z13TOidPvUNuPnnue\n2nbetZPaPvbQh5LjnXZQ8zC4326aO2ARjuidXYhMULALkQkKdiEyQcEuRCYo2IXIBAW7EJlw00hv\nrMMFwGW5SCRb7KtYIahNtoguQ1iJxIlFNMgJiVpvRRqPFfkqs3pyrx99k86pDq+ltnbgR7PVpDZK\ncDGj9Y1k4Lis3epLunpnFyITFOxCZIKCXYhMULALkQkKdiEyQcEuRCYsSXozsxMAZgC0AbTcfXf0\n+41mC2fPTyRtIyMjdF6lUiYWLlmUilEtLj6v47w2GT1ikP0VvZ56IMcstg6agbTRCtprdTxovbVI\nVWjTxg3J8S0b19M55aFharv99q3UtnHjuoU71qMQPK8GaRkFAFbi17McXevgfG1SUK7ArmX3iDc4\nvjw6+z9193QECyFuGvQxXohMWGqwO4Afm9nLZrZnORwSQqwMS/0Y/xF3P2tmmwE8b2avu/tPr/+F\n3ovAHgDYtn37Ek8nhFgsS3pnd/ezvf/PA3gGwIOJ39nr7rvdffeGDRuXcjohxBJYdLCb2bCZrbn2\nGMAfADi0XI4JIZaXpXyM3wLgmV5xvhKAv3L3v4kmTF68hO/81dNJ29hG/q6/adOm5HiR9ZICsGH9\nGmrbecft1Da2gcs4TPCKijKuSLeg4HwdYrICX6ySMWkTaLW5FDlzaYbPq6Uz0d43lr6WANAMFmvT\nGL8/fv73/5f7MTubHL931y46Z2gtv3ciacvbLT6N9WsCAJJJ12YXMyCasehgd/fjAH5zsfOFEP1F\n0psQmaBgFyITFOxCZIKCXYhMULALkQl9LTjZaLZw4kw6Z+bs+GU6b3h4PDk+NMglo3Igyx06dIza\n7rv3N6jt/bvuTPsxVOV+lPgSW9RHLch4KnSC12iSgTd3pUanjE9eDGzpnm0AMH6Rzzs/eSk5Xhwa\noHMuXUzPAYCJSX5/tBq84OSzZ9Jq8Nt3n6BzHrjvH1Pbtvfx7LuhkSFq64DLcuw2sEKFz6GWKNtT\nCJEFCnYhMkHBLkQmKNiFyAQFuxCZ0NfdeLMCqgPpnWsL2uo0SYJBrcFfqzpl/tTemeA7u1M/f4na\nDr72RnJ88xhPnrnn7vdT261bt1Bbp92gtumpK9R2+pdp5eLqLN+Ndw+kiyrfEa6SBCUAOPPWW8nx\ni7WrdM6lGn9ec68fpbYP3LWT2jZvSNe8O3ws7R8AuPP76tSZc9Q2tiVddw8Adty2jdqqlfQanzx9\nms45dizdRmt6aprO0Tu7EJmgYBciExTsQmSCgl2ITFCwC5EJCnYhMqGv0pt7G416um5ZhcgPAODt\ntDQ0R+qcAUC9FUhGQZZMq8OPOXkinfjx1ls8aeXYUZ50c/fOHdSGTp37MZeuqwYAa7e8Lzk+ODJK\n5wyt5ZLR4ABP7jj1Bn9uh/cfTo5PjfPEmmoxaJ/ES+Hhlf0Hqe3ee+5Ojm8a48/51AWe4DM4xuXS\nqXPnqe10IKNNj19Ijr+071U+ZzotsUXJRHpnFyITFOxCZIKCXYhMULALkQkKdiEyQcEuRCbMK72Z\n2eMA/gjAeXe/tze2AcAPAOwAcALAp9yd7/n38HYbtStT6fME0puRTLlidZjP6QTtdoLab/U6rxVW\nIP2marM8W+vcKS41TZ7g0tVQicuDo5URaiuuS9f4s1vvoHMuV3gWYKM2R20vv/xzajv/9onkeJu0\nYwKA6tq11DYwxJ9zvcYz+l59NS1f/aPf+ACd04nunaM8+27nbbxLcXOW31fjJ9OZdFeC2oBGZcqo\nruH8/CWAh98z9hiAF9x9F4AXej8LIW5i5g32Xr/1977EPALgid7jJwB8Ypn9EkIsM4v9m32Lu1/7\n7PEOuh1dhRA3MUveoPNuv2L6h4KZ7TGzfWa2rxb8/SeEWFkWG+zjZrYVAHr/0y8Fu/ted9/t7rsH\nBgYXeTohxFJZbLA/C+DR3uNHAfxoedwRQqwUC5HevgfgYwDGzOwMgC8B+AqAJ83scwBOAvjUwk7n\nKCGdvuRRsUFiqwzyPwu4NAF0SoHMF9hmrqT9qFb5MhaagY8NLhldmOUFJyeb6SwpADjbei05ft8t\nvDjkpvvuo7bx41we3H/gF9R2nmSArVnPs806JS4btVt8PYYC2XZ6Ml2A8+Crr9A5UYpdMWjjdPHM\nKWrbMpoufAkAGzent7zWnHybzpmcS99XHsjK8wa7u3+GmH5vvrlCiJsHfYNOiExQsAuRCQp2ITJB\nwS5EJijYhciE/vZ6KxZQGiYZbB0ud1ydSEtNV2d4RlmxVKa2DnhWkxvPNqsTF3fdv5vOuXqJy2SV\nKvexbPzSbFo/Rm3nX07LYc05LhmNjvJilLMbuVTWaAf9+RrpxZqe5NesUAiyzdbwop5XiSQKAKyF\nYDm4Pw4fScuXAFAPZLmtW26htknnBUS3b7szOV45wjP9Wlf5c2bonV2ITFCwC5EJCnYhMkHBLkQm\nKNiFyAQFuxCZ0FfpDcUS2qObk6ZqhbtSaaRll6sX0hlNALjmAqDR4vJJK5AAN2zemhwvGJdx6m3+\nelospmVIACiO8OKLd3/kn1Bb48yZ5LjVuXTlDd7frhms1VyNH3N2Ni01bVjLi4ROXeAyZbPGpati\nid871Ur62pSDTDnUeYbd0VcPUVvr/dzH23em5TUAeP3tt5LjUw1+vFozfc06Qdab3tmFyAQFuxCZ\noGAXIhMU7EJkgoJdiEzo6258ZXAYd977W2lHggSDUxPp9kRBWS+0W3ynuMU3LMNEmOFqOjFh+u3j\ndE7Z+c5uo3aV2gaDFkSVYPe8XU/XJms6T4RpBy2DOp2gLlygXLDd4js+wNsuXZnjyR0njvG2S5vG\neGLQ2g3pm6Qe3B8lbkJ9mrevenM/36mvBO+rg7vuSo4Xh7lyUa4OJMctUKH0zi5EJijYhcgEBbsQ\nmaBgFyITFOxCZIKCXYhMWEj7p8cB/BGA8+5+b2/sywD+GMC1zIUvuvtz8x2rXa9j6tSJpG3z+nV8\n4rmzyeHS9CU6pWz8dcwK/Gl7YGtfnEiOdxpcMuq0ufSGctCGapof8+iP/5baZs//Mu3H3e+nc1rB\nS36nzSW7Voc/txbS+tW2nbvonN/67Q9T21OP/wW1nTjOpc82kaLWBnLd1Axf+3bQVqwY2I6+8Qa1\nlUhSzoYt6aQxABhdn5YUo6Sghbyz/yWAhxPjX3f3+3v/5g10IcTqMm+wu/tPAVzsgy9CiBVkKX+z\nf97MDpjZ42YWfJdNCHEzsNhg/yaAnQDuB3AOwFfZL5rZHjPbZ2b75hZR61oIsTwsKtjdfdzd2+7e\nAfAtAA8Gv7vX3Xe7++7BYV70Xgixsiwq2M3s+vpMnwTAMwCEEDcFC5HevgfgYwDGzOwMgC8B+JiZ\n3Q/AAZwA8CcLOZm3m6hdTtdIm5zk8klrIj2nUOPSjwfZWgjkCSvw178KmVdEkFHW4j5aJMv98m1q\nOjOZliIBoOVpyev8ZFo2BIDtc+lMOSDOerPouXXSWW/VkXS2FgDcdu891LbrgQ9R2/ET6RpuAFCb\nTj/vUiAblkvcRxvhmWid4L2z0eYZgkfeSGf0rR1Py6gAUCa15upB3bp5g93dP5MY/vZ884QQNxf6\nBp0QmaBgFyITFOxCZIKCXYhMULALkQl9LTjZqM3hzBuvJW1jHS4ZFFppaasWFIdEJch6s6DAYp37\nMUxq+TXavABkqciXuBxk2JV43UBU2rzo4VQ9/dyOv8azru76KE996ASFL0tFLlEVSdZh1HapVeTX\n86F//i+orT7Lv5n59z/+X8nxucs8Y9IC6W2UtAADgHoQTp0ir2I5VE23qJoYf4fOcVIktEkKfQJ6\nZxciGxTsQmSCgl2ITFCwC5EJCnYhMkHBLkQm9FV6azeamHn7XNI2QgoUAsDJc6eT47NFLguVB6vU\ntq7K5Z8tgZxUqKclwFaZL2ORyCoAgKAoJoLsOzRq/HzMx0tTdM6pg4ep7eKldJ89AJi5ynvVFchz\nO/0mz+b73//zb6hty+YN1FYlfc8AoE6SzVpNnoVWaExTm03w+3RwdCO1DQ0MUlvJ0nLZUNDrbe3o\naHL81FHeE0/v7EJkgoJdiExQsAuRCQp2ITJBwS5EJvR1N75aqeD2229L2sYPHaTzzrbSu8+ljbyF\nT6XEd9ybQZ2ucoPvMFeRPubwBr5rWnB+LmvxpAWQtkUA0Apq1zkph9cJkkWef/pJapu9wnem1xe5\nKrB5S7qS8NkDv6Bzju17kdrWbhiiNgtqABaa6aShsvM1rJT4e2CnMUNts1N8p75ivL1ZqZjeqd+4\njisQY7ekE3LKFa7+6J1diExQsAuRCQp2ITJBwS5EJijYhcgEBbsQmbCQ9k+3AvgOgC3otnva6+7f\nMLMNAH4AYAe6LaA+5e68sBeAjhnq1XSdsUsFXheuuvWW5HizzJNd2sHrmK3h8+pXuPR2ZS4toxWM\nH68U1JlrOk/GCPKCwhZVc6T90/iFdAISAEwV+MlGgmSjzet5cke5kr7O7aCmnYPLRp0CXysL7oO1\nO3emj0ckOQBo1bit1g7qFwZJVOVAzitZev2tzdtyXT6fbg3VXmINuhaAP3P3ewA8BOBPzeweAI8B\neMHddwF4ofezEOImZd5gd/dz7v5K7/EMgCMAtgF4BMATvV97AsAnVspJIcTSuaG/2c1sB4APAngR\nwBZ3v/bZ8B10P+YLIW5SFhzsZjYC4CkAX3D3d32H0t0dSBeyNrM9ZrbPzPbV6/zrlUKIlWVBwW5m\nZXQD/bvu/nRveNzMtvbsWwGcT811973uvtvdd0cVRYQQK8u8wW5mhm4/9iPu/rXrTM8CeLT3+FEA\nP1p+94QQy8VCst5+B8BnARw0s/29sS8C+AqAJ83scwBOAvjUfAdqtlp4Z+JC0nYxqKtWGU5nDLVq\nXAZpB9qVreefMFplnqV28WpaCvnlFJdqKoOBHBO0rwo6VGEwqHnXbKYzwBqBvLZuLT/ecORjkUtl\nzUJaYvMSn1Or8ey14eF0zTUAsEGedThXS0tR5Sqf02qNc1sg2Y2MpjP9AGBjkKFpHeJjkMHWIBJm\nMXj7njfY3f1nAJg4+nvzzRdC3BzoG3RCZIKCXYhMULALkQkKdiEyQcEuRCb0teCkw1FvpyUgH+AF\nBQeH1iTHp6Ym6Jx6kxcUrA7yzKtqiS/J1XJahpoMktdKTa6hlYvcVipyP8qspxGA2Zl0YcnSIC/A\nWSpxGaoWtKiamQkyx0hGXwfBtyiNP+eBMS5rXZzkLaouXkwnYlbKXBIdGQrWI5Awq4FMuWbdempz\nslb1Br/O9dn0Onac39t6ZxciExTsQmSCgl2ITFCwC5EJCnYhMkHBLkQm9FV6q1SruO3OdAHAgWEu\nrVy5mpaTilXufof0hwOATpBRxgU7oEVkudFAVrFAQosoBEUlg9qcME8bS1VelLFT4TJUgxwPAJpF\nvloFS2dsXZ3mveMGBnmW19VZno04NZkspQAAqE+nZblWIL1VKrzoUnEwLQMDQDuQvVpEcgaADrkh\n287vgSq5ZoWgR6De2YXIBAW7EJmgYBciExTsQmSCgl2ITOjrbrzB6C5zpcITNZDejMemTbyu1/AI\nT6xZu5YnOly5wOuP1Uj7JwPfYa4M8F3fYrDj3glsVuQJF5Wh9PmKQYKPkQQfACiQWnIAsLbMVYhy\nOb2zbtWoBh3f3Z+ZnqG2Zp3v1A9WyDoWeZukVou3XWo0+HqgxZ/blau8rZiReomtBvexSdo8tdu8\njp/e2YXIBAW7EJmgYBciExTsQmSCgl2ITFCwC5EJ80pvZnYrgO+g25LZAex192+Y2ZcB/DGAa/2c\nvujuz0XHcne0W2lpIJLeGkRmGBrkyR3vW38LtV2Y4IkTc6R9EgB0SGOcsvMkhwKpLwYAneBcFiU0\nDA5SW4m0VyoH61siMhkQS2+RZMeumQf9iaLj1QJ5LUoa6pAElIFAEg17b9HmSEC7w6/15UvpWngA\nMDiQvjaFyA/n9w5jITp7C8CfufsrZrYGwMtm9nzP9nV3/y83fFYhRN9ZSK+3cwDO9R7PmNkRANtW\n2jEhxPJyQ3+zm9kOAB8E8GJv6PNmdsDMHjcz/nUqIcSqs+BgN7MRAE8B+IK7TwP4JoCdAO5H953/\nq2TeHjPbZ2b7ajX+NUQhxMqyoGA3szK6gf5dd38aANx93N3b7t4B8C0AD6bmuvted9/t7rsHBvjG\nkhBiZZk32K27LfxtAEfc/WvXjW+97tc+CeDQ8rsnhFguFrIb/zsAPgvgoJnt7419EcBnzOx+dOW4\nEwD+ZL4DmRnPhgqkplu3b0+OTwQZalPTXOooVvjT3rx1K7WNlNNSX6nMj1cIpCYPJLtWIMs1+TSU\niI9s3YFYugouC21bBADtatpWIdIgAFyd5e2kpjvcNjjK68INV9YlxxutoIVW0LJr3br08QCgUgpk\nymCNHeR8QXYjjaNAKl3IbvzPkBYXQ01dCHFzoW/QCZEJCnYhMkHBLkQmKNiFyAQFuxCZ0N+Ck2a0\n8GEk/1RI66LRUd4yqhNkBXUCPWmgxLPDKoW0FGKFqLUPt7XbXP6ZC2So+hyfVyqk1zfKevOgxROY\nLATAuDJEJbvGAC8qORh86coC6fDKFJdZZ+rp7Lu5Gl/DoWFekHTNGn7PVYqBThkUgmy10z4WKjyr\nk3uv9k9CZI+CXYhMULALkQkKdiEyQcEuRCYo2IXIhL5Kbw6guYjXlxLReCrVINvMgiKQUdFD47Yi\nsUWFAWlGE2J5DQUuNVWHebFE7xD/S/x5FYLnbMFzi2yMcpFfs3VDXPIaHeXZZjPreJGk6Zl0jzgn\nMioADFUD+TWQ1wqBpNsJilGWPX09S0EGW6NBJMzgkuidXYhMULALkQkKdiEyQcEuRCYo2IXIBAW7\nEJnQd+mt1UlrA0bGAaBIJIgoUy6Uk4LMoMhWIAUAg1wn1OZ4rfzZOZ4BFkmARjLbAKBEZKPIxzDn\nLSiKGRacJBl9neA6VytBUcxgPUaGecHJNaOjyfFW8Kw7QTHKZo33nGsFWYzFIIOtTKTgTpPfH/Rt\nOuoRyI8mhPh1QsEuRCYo2IXIBAW7EJmgYBciE+bdjTezAQA/BVDt/f4P3f1LZnYHgO8D2AjgZQCf\ndfdg+7Bb66xNanGVg8SEItmtbLeDfeQgYSEqucb8A4BiO70zXQwSQmauXKE2mswAoBLUjIvyT9ir\nd6RctFtBfbTA1g6SO1rNdF21qLmnB0Xtpmf5OtbrNWobHBpKjoftmCxIsAqSr9hzBoBmUIuw42lf\nHHw9WqRWoi9xN74O4Hfd/TfRbc/8sJk9BODPAXzd3e8CcAnA5xZwLCHEKjFvsHuXay+r5d4/B/C7\nAH7YG38CwCdWxEMhxLKw0P7sxV4H1/MAngfwFoDL7v9Qr/kMgG0r46IQYjlYULC7e9vd7wewHcCD\nAO5e6AnMbI+Z7TOzffXg22RCiJXlhnbj3f0ygJ8A+G0A68z+YSdjO4CzZM5ed9/t7rurg3xzRgix\nsswb7Ga2yczW9R4PAvh9AEfQDfp/3fu1RwH8aKWcFEIsnYUkwmwF8ISZFdF9cXjS3f/azF4D8H0z\n+08A/h+Aby/khKwdUpAfwdsTBTJDMzigBfNagR+tZlqGagcJC/Uml6c8SO5ocqUmrHkHkrjiQSpM\nO8qSKXH5pxRIVKUg8YNRI+sLAF7iSTKsLRcAgNg8asuFaPH5cy4HzzmSMDvk/m55cM2ILZKV5w12\ndz8A4IOJ8ePo/v0uhPgVQN+gEyITFOxCZIKCXYhMULALkQkKdiEywaistRInM7sA4GTvxzEAE307\nOUd+vBv58W5+1fy43d03pQx9DfZ3ndhsn7vvXpWTyw/5kaEf+hgvRCYo2IXIhNUM9r2reO7rkR/v\nRn68m18bP1btb3YhRH/Rx3ghMmFVgt3MHjazN8zsTTN7bDV86PlxwswOmtl+M9vXx/M+bmbnzezQ\ndWMbzOx5MzvW+3/9KvnxZTM721uT/Wb28T74cauZ/cTMXjOzw2b2b3vjfV2TwI++romZDZjZL8zs\n1Z4f/7E3foeZvdiLmx+YGa9KmsLd+/oPQBHdslZ3AqgAeBXAPf32o+fLCQBjq3DejwJ4AMCh68b+\nM4DHeo8fA/Dnq+THlwH8uz6vx1YAD/QerwFwFMA9/V6TwI++rgm6rflGeo/LAF4E8BCAJwF8ujf+\nFwD+zY0cdzXe2R8E8Ka7H/du6envA3hkFfxYNdz9pwAuvmf4EXQLdwJ9KuBJ/Og77n7O3V/pPZ5B\ntzjKNvR5TQI/+op3WfYir6sR7NsAnL7u59UsVukAfmxmL5vZnlXy4Rpb3P1c7/E7ALasoi+fN7MD\nvY/5K/7nxPWY2Q506ye8iFVck/f4AfR5TVaiyGvuG3QfcfcHAPwhgD81s4+utkNA95UdcSflleSb\nAHai2yPgHICv9uvEZjYC4CkAX3D36ett/VyThB99XxNfQpFXxmoE+1kAt173My1WudK4+9ne/+cB\nPIPVrbwzbmZbAaD3//nVcMLdx3s3WgfAt9CnNTGzMroB9l13f7o33Pc1SfmxWmvSO/cNF3llrEaw\nvwRgV29nsQLg0wCe7bcTZjZsZmuuPQbwBwAOxbNWlGfRLdwJrGIBz2vB1eOT6MOaWLco4LcBHHH3\nr11n6uuaMD/6vSYrVuS1XzuM79lt/Di6O51vAfj3q+TDnegqAa8CONxPPwB8D92Pg010//b6HLo9\n814AcAzA3wHYsEp+/HcABwEcQDfYtvbBj4+g+xH9AID9vX8f7/eaBH70dU0A3IduEdcD6L6w/Ifr\n7tlfAHgTwP8AUL2R4+obdEJkQu4bdEJkg4JdiExQsAuRCQp2ITJBwS5EJijYhcgEBbsQmaBgFyIT\n/j8C1XqoC6PSOQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk_djf8anBK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "\n",
        "# based on the lifted scheme paper\n",
        "def create_deep_base_network(input_dim,loss_type,num_classes=0,transfer=False,freeze_weights=False):\n",
        "  weights='imagenet' if transfer else None\n",
        "  conv_base = ResNet50(weights=weights, include_top=False, input_shape=input_dim)\n",
        "\n",
        "  if freeze_weights:\n",
        "    for layer in conv_base.layers:\n",
        "      layer.trainable=False\n",
        "  \n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Input(input_dim))\n",
        "  model.add(conv_base)\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.BatchNormalization())\n",
        "\n",
        "  if loss_type=='classification':\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "  else:\n",
        "    model.add(layers.Dense(64, activation=None))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def create_shallow_network(input_dim,loss_type,num_classes=0):\n",
        "  model=tf.keras.Sequential()\n",
        "  model.add(layers.Input(input_dim))\n",
        "  model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=5, padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=2, padding='same'))\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  if loss_type=='classification':\n",
        "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Dense(num_classes,activation='softmax'))\n",
        "  else:\n",
        "    model.add(tf.keras.layers.Dense(256, activation=None))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "  return model\n",
        "\n",
        "def construct_model(model_type,input_dim,loss_type,num_classes,transfer=False,freeze_weights=False):\n",
        "  if model_type=='shallow':\n",
        "    model=create_shallow_network(input_dim,loss_type,num_classes)\n",
        "  elif model_type=='deep':\n",
        "    model=create_deep_base_network(input_dim,loss_type,num_classes,transfer,freeze_weights)\n",
        "\n",
        "  if loss_type =='triplet':\n",
        "    model.add(tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)))\n",
        "  return model\n",
        "\n",
        "def construct_loss(loss_type,margin):\n",
        "  if loss_type=='triplet':\n",
        "    loss=tfa.losses.TripletSemiHardLoss(margin=margin)\n",
        "  elif loss_type=='lifted':\n",
        "    loss=tfa.losses.LiftedStructLoss(margin=margin)\n",
        "  elif loss_type=='classification':\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy()\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlxiWw0svGrf",
        "colab_type": "code",
        "outputId": "dc9f59a3-5100-482f-9cab-efddc90d14bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# tune lr\n",
        "\n",
        "lrs=[1e-2,1e-3,1e-4,1e-5,1e-6]\n",
        "# lrs=[1e-6]\n",
        "model_type='deep'\n",
        "transfer=True\n",
        "freeze_weights=False\n",
        "\n",
        "margin=1.0\n",
        "\n",
        "model_dir=os.path.join(dataset_dir,model_type)\n",
        "if not os.path.isdir(model_dir):\n",
        "  os.mkdir(model_dir)\n",
        "\n",
        "num_epochs=30\n",
        "\n",
        "fig,ax=plt.subplots(2,3)\n",
        "ax=ax.ravel()\n",
        "for lr_index,lr in enumerate(lrs):\n",
        "  model=construct_model(model_type,new_input_dim,loss_type,num_classes,transfer,freeze_weights)\n",
        "  loss=construct_loss(loss_type,margin)\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(lr),loss=loss)\n",
        "\n",
        "  history = model.fit(\n",
        "      train_dataset,\n",
        "      epochs=num_epochs)\n",
        "\n",
        "  ax[lr_index].set_title('Loss for lr_%s'%(str(lr)))\n",
        "  ax[lr_index].plot(np.arange(num_epochs),history.history['loss'],'r',label='train_loss_lr_%s'%(str(lr)))\n",
        "  \n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(model_dir,'loss_plot_lr_tune_%s_transfer_%s_freeze_%s_%s_%s.png'%(model_type,transfer,freeze_weights,loss_type,margin)))\n",
        "plt.close()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "50/50 [==============================] - 10s 206ms/step - loss: 10.2924\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.8001\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.8982\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.8379\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.7307\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.8476\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.7460\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.8094\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 6.8544\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: nan\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.8031\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 6.8181\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 2s 50ms/step - loss: 6.7757\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 6.7375\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 6.8040\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.7976\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 6.8952\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.7837\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.7965\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.7968\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 6.8634\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.8399\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 6.8215\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.7091\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.8678\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.7759\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 6.9303\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 6.9048\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 6.8557\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.8242\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 11s 212ms/step - loss: 30.0034\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 38.9014\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 35.6655\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 35.2073\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 34.2411\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 65.2296\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 50.9228\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 43.0813\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 35.0887\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 25.6663\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 26.0485\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 53.8815\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 54.8821\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 32.7651\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 27.9822\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 22.4869\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 17.6472\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 21.1577\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 18.9658\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 15.0561\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 14.5517\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 20.4349\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 17.8200\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 15.6104\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 14.2218\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 24.7379\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 52.4114\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 6.8412\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.8183\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 6.8828\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 9s 182ms/step - loss: 25.1138\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 25.3639\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 19.8209\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 2s 50ms/step - loss: 21.9981\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 23.0149\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 21.5488\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 17.9106\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 19.0524\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 18.7438\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 17.5621\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 20.5515\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 18.8129\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 19.1044\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 17.6176\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 16.2980\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 15.5585\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 16.9160\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 16.3992\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 17.3732\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 16.4212\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 14.5553\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 16.1443\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 14.3678\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 15.4467\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 15.1637\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 15.0388\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: nan\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 6.8722\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.7795\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.8497\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 9s 187ms/step - loss: 25.6061\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 26.0982\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 26.3953\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 28.7258\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 25.7184\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 25.8706\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 23.1755\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 23.3399\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 24.1381\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 25.5103\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 26.0503\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 25.6325\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 24.0735\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 23.6174\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 24.3102\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 23.7824\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 22.7997\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 18.6610\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 24.1850\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 2s 49ms/step - loss: 21.4786\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 2s 50ms/step - loss: 24.3453\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 20.2368\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 20.9795\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 21.9011\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 22.5933\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 20.8697\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 22.4196\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 22.0144\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 22.9311\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 24.0592\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 22.2241\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 25.7509\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 26.5906\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 25.9804\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 22.9246\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 25.5734\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 26.4356\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 23.7530\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 25.0053\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 27.4133\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 24.8672\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 23.7806\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 24.6833\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 25.7714\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 25.6685\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 26.2583\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 26.6122\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 26.3344\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 29.2412\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 24.3001\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 26.2700\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 28.2294\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 2s 50ms/step - loss: 24.4351\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 24.7398\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 26.4218\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 28.2207\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 23.0186\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 28.6461\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 2s 49ms/step - loss: 25.2192\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 27.8505\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E19n3qkFVyc4",
        "colab_type": "code",
        "outputId": "bd2c3e68-909b-4bab-8c01-f7e963d54f0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train model\n",
        "\n",
        "lr=1e-5\n",
        "\n",
        "model_type='deep'\n",
        "transfer=True\n",
        "freeze_weights=False\n",
        "\n",
        "margin=1.0\n",
        "\n",
        "model_dir=os.path.join(dataset_dir,model_type)\n",
        "if not os.path.isdir(model_dir):\n",
        "  os.mkdir(model_dir)\n",
        "\n",
        "num_epochs=50\n",
        "\n",
        "model=construct_model(model_type,new_input_dim,loss_type,num_classes,transfer,freeze_weights)\n",
        "loss=construct_loss(loss_type,margin)\n",
        "\n",
        "# Compile the model\n",
        "metrics=[]\n",
        "if loss_type=='classification':\n",
        "  metrics=['accuracy']\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr),loss=loss,metrics=metrics)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "filepath=os.path.join(model_dir,'final_%s_%s_transfer_%s_freeze_%s_margin_%s_lr_%s.h5'\n",
        "    %(loss_type,model_type,transfer,freeze_weights,margin,lr))\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_loss',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "callbacks = [checkpoint]\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=test_dataset,\n",
        "    callbacks=callbacks)\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(num_epochs),history.history['loss'],'r',label='train_loss')\n",
        "plt.plot(np.arange(num_epochs),history.history['val_loss'],'b',label='val_loss')\n",
        "plt.legend()\n",
        "filepath=os.path.join(model_dir,'final_loss_plot_%s_%s_transfer_%s_freeze_%s_margin_%s_lr_%s.png'\n",
        "%(loss_type,model_type,transfer,freeze_weights,margin,lr))\n",
        "plt.savefig(filepath)\n",
        "plt.close()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "    938/Unknown - 53s 56ms/step - loss: 33.0522\n",
            "Epoch 00001: val_loss improved from inf to 63.63127, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 69s 74ms/step - loss: 33.0522 - val_loss: 0.0000e+00\n",
            "Epoch 2/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 27.0677\n",
            "Epoch 00002: val_loss improved from 63.63127 to 28.13180, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 64s 68ms/step - loss: 27.0677 - val_loss: 28.1318\n",
            "Epoch 3/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 25.4328\n",
            "Epoch 00003: val_loss improved from 28.13180 to 25.18558, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 66s 70ms/step - loss: 25.4328 - val_loss: 25.1856\n",
            "Epoch 4/50\n",
            "936/938 [============================>.] - ETA: 0s - loss: 24.1200\n",
            "Epoch 00004: val_loss improved from 25.18558 to 22.76600, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 64s 68ms/step - loss: 24.1186 - val_loss: 22.7660\n",
            "Epoch 5/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 23.3777\n",
            "Epoch 00005: val_loss improved from 22.76600 to 21.77829, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 64s 68ms/step - loss: 23.3777 - val_loss: 21.7783\n",
            "Epoch 6/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 22.5591\n",
            "Epoch 00006: val_loss improved from 21.77829 to 21.18285, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 65s 69ms/step - loss: 22.5591 - val_loss: 21.1829\n",
            "Epoch 7/50\n",
            "936/938 [============================>.] - ETA: 0s - loss: 21.5895\n",
            "Epoch 00007: val_loss improved from 21.18285 to 20.81868, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 64s 68ms/step - loss: 21.5950 - val_loss: 20.8187\n",
            "Epoch 8/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 20.8741\n",
            "Epoch 00008: val_loss improved from 20.81868 to 19.19631, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 64s 68ms/step - loss: 20.8741 - val_loss: 19.1963\n",
            "Epoch 9/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 19.9590\n",
            "Epoch 00009: val_loss improved from 19.19631 to 18.00505, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 64s 69ms/step - loss: 19.9590 - val_loss: 18.0051\n",
            "Epoch 10/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 19.1497\n",
            "Epoch 00010: val_loss improved from 18.00505 to 17.22256, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 64s 68ms/step - loss: 19.1497 - val_loss: 17.2226\n",
            "Epoch 11/50\n",
            "936/938 [============================>.] - ETA: 0s - loss: 18.1907\n",
            "Epoch 00011: val_loss improved from 17.22256 to 16.11643, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 64s 68ms/step - loss: 18.1877 - val_loss: 16.1164\n",
            "Epoch 12/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 17.3975\n",
            "Epoch 00012: val_loss improved from 16.11643 to 15.83292, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 66s 71ms/step - loss: 17.3975 - val_loss: 15.8329\n",
            "Epoch 13/50\n",
            "936/938 [============================>.] - ETA: 0s - loss: 16.7047\n",
            "Epoch 00013: val_loss improved from 15.83292 to 15.80743, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 65s 69ms/step - loss: 16.7060 - val_loss: 15.8074\n",
            "Epoch 14/50\n",
            "936/938 [============================>.] - ETA: 0s - loss: 15.8859\n",
            "Epoch 00014: val_loss improved from 15.80743 to 14.54493, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 65s 69ms/step - loss: 15.8890 - val_loss: 14.5449\n",
            "Epoch 15/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 15.1605\n",
            "Epoch 00015: val_loss improved from 14.54493 to 14.00910, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 64s 69ms/step - loss: 15.1605 - val_loss: 14.0091\n",
            "Epoch 16/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 14.5166\n",
            "Epoch 00016: val_loss improved from 14.00910 to 13.40682, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 65s 69ms/step - loss: 14.5166 - val_loss: 13.4068\n",
            "Epoch 17/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 13.7920\n",
            "Epoch 00017: val_loss improved from 13.40682 to 13.08760, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 64s 68ms/step - loss: 13.7920 - val_loss: 13.0876\n",
            "Epoch 18/50\n",
            "936/938 [============================>.] - ETA: 0s - loss: 13.1837\n",
            "Epoch 00018: val_loss improved from 13.08760 to 12.66998, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 64s 69ms/step - loss: 13.1829 - val_loss: 12.6700\n",
            "Epoch 19/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 12.4351\n",
            "Epoch 00019: val_loss improved from 12.66998 to 12.37777, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 64s 68ms/step - loss: 12.4351 - val_loss: 12.3778\n",
            "Epoch 20/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 11.9220\n",
            "Epoch 00020: val_loss improved from 12.37777 to 11.94134, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 64s 68ms/step - loss: 11.9220 - val_loss: 11.9413\n",
            "Epoch 21/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 11.3333\n",
            "Epoch 00021: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 11.3333 - val_loss: 12.1816\n",
            "Epoch 22/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 10.7926\n",
            "Epoch 00022: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 10.7926 - val_loss: 12.2318\n",
            "Epoch 23/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 10.2630\n",
            "Epoch 00023: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 10.2630 - val_loss: 11.9766\n",
            "Epoch 24/50\n",
            "936/938 [============================>.] - ETA: 0s - loss: 9.8559\n",
            "Epoch 00024: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 9.8550 - val_loss: 12.2609\n",
            "Epoch 25/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 9.3195\n",
            "Epoch 00025: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 9.3195 - val_loss: 12.3613\n",
            "Epoch 26/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 8.9479\n",
            "Epoch 00026: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 8.9479 - val_loss: 12.9474\n",
            "Epoch 27/50\n",
            "936/938 [============================>.] - ETA: 0s - loss: 8.5119\n",
            "Epoch 00027: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 62ms/step - loss: 8.5138 - val_loss: 12.7722\n",
            "Epoch 28/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 8.0954\n",
            "Epoch 00028: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 8.0954 - val_loss: 13.0298\n",
            "Epoch 29/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 7.7390\n",
            "Epoch 00029: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 58s 62ms/step - loss: 7.7390 - val_loss: 13.4860\n",
            "Epoch 30/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 7.3675\n",
            "Epoch 00030: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 7.3675 - val_loss: 14.1673\n",
            "Epoch 31/50\n",
            "936/938 [============================>.] - ETA: 0s - loss: 7.0285\n",
            "Epoch 00031: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 7.0267 - val_loss: 14.7606\n",
            "Epoch 32/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 6.6403\n",
            "Epoch 00032: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 58s 62ms/step - loss: 6.6403 - val_loss: 15.1827\n",
            "Epoch 33/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 6.4527\n",
            "Epoch 00033: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 62ms/step - loss: 6.4527 - val_loss: 16.3453\n",
            "Epoch 34/50\n",
            "936/938 [============================>.] - ETA: 0s - loss: 6.0800\n",
            "Epoch 00034: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 6.0843 - val_loss: 16.0405\n",
            "Epoch 35/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 5.7983\n",
            "Epoch 00035: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 5.7983 - val_loss: 17.2213\n",
            "Epoch 36/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 5.4719\n",
            "Epoch 00036: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 5.4719 - val_loss: 18.2092\n",
            "Epoch 37/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 5.1912\n",
            "Epoch 00037: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 5.1912 - val_loss: 19.1026\n",
            "Epoch 38/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 4.9576\n",
            "Epoch 00038: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 4.9576 - val_loss: 19.0770\n",
            "Epoch 39/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 4.6950\n",
            "Epoch 00039: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 4.6950 - val_loss: 19.7781\n",
            "Epoch 40/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 4.3929\n",
            "Epoch 00040: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 4.3929 - val_loss: 21.1686\n",
            "Epoch 41/50\n",
            "936/938 [============================>.] - ETA: 0s - loss: 4.1337\n",
            "Epoch 00041: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 4.1323 - val_loss: 21.8242\n",
            "Epoch 42/50\n",
            "936/938 [============================>.] - ETA: 0s - loss: 3.8696\n",
            "Epoch 00042: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 3.8696 - val_loss: 23.0441\n",
            "Epoch 43/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 3.7513\n",
            "Epoch 00043: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 3.7513 - val_loss: 23.4720\n",
            "Epoch 44/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 3.4541\n",
            "Epoch 00044: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 3.4541 - val_loss: 24.9680\n",
            "Epoch 45/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 3.2553\n",
            "Epoch 00045: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 60s 63ms/step - loss: 3.2553 - val_loss: 25.8973\n",
            "Epoch 46/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 3.0849\n",
            "Epoch 00046: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 3.0849 - val_loss: 26.3130\n",
            "Epoch 47/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 2.8445\n",
            "Epoch 00047: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 2.8446 - val_loss: 27.3926\n",
            "Epoch 48/50\n",
            "936/938 [============================>.] - ETA: 0s - loss: 2.6887\n",
            "Epoch 00048: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 2.6900 - val_loss: 28.6252\n",
            "Epoch 49/50\n",
            "936/938 [============================>.] - ETA: 0s - loss: 2.5959\n",
            "Epoch 00049: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 2.6018 - val_loss: 28.8702\n",
            "Epoch 50/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 2.3765\n",
            "Epoch 00050: val_loss did not improve from 11.94134\n",
            "938/938 [==============================] - 59s 63ms/step - loss: 2.3765 - val_loss: 31.6922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-uo2QKnMRkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate performance of model using Recall@K\n",
        "\n",
        "# retrieve k nearest neighbors based on embeddings\n",
        "\n",
        "\n",
        "# pairwise distance matrix computation: \n",
        "# https://stackoverflow.com/questions/37009647/compute-pairwise-distance-in-a-batch-without-replicating-tensor-in-tensorflow\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def forward(A):\n",
        "  r = tf.reduce_sum(A*A, 1)\n",
        "  r = tf.reshape(r, [-1, 1])\n",
        "  D = r - 2*tf.matmul(A, tf.transpose(A)) + tf.transpose(r)\n",
        "  return D\n",
        "# A = tf.constant([[1, 1], [2, 2], [3, 3]])\n",
        "# res=forward(A)\n",
        "# print(res)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "D: 2d array num_samplesxnum_samples (num_samples >=2)\n",
        "test_labels: 1d array num_samples\n",
        "k: int # nearest neighbors >=1\n",
        "\"\"\"\n",
        "def compute_recall_at_k(Dist_matrix,test_labels,k):\n",
        "  num_samples=Dist_matrix.shape[0]\n",
        "  recall=0\n",
        "  for sample_index in range(num_samples):\n",
        "    ind_samples_sorted_by_distance=np.argsort(Dist_matrix[sample_index])\n",
        "    # assert ind_samples_sorted_by_distance[0]==sample_index\n",
        "    ind_samples_sorted_by_distance=ind_samples_sorted_by_distance[1:]# exclude the sample in question\n",
        "    \n",
        "    ind_nearest_k_neighbors=ind_samples_sorted_by_distance[:k]\n",
        "    labels_nearest_k_neighbors=test_labels[ind_nearest_k_neighbors]\n",
        "    true_label=test_labels[sample_index]\n",
        "\n",
        "    if true_label in labels_nearest_k_neighbors:\n",
        "      recall+=1\n",
        "\n",
        "  recall*=(1.0/num_samples)\n",
        "\n",
        "  return recall\n",
        "\n",
        "\n",
        "# test compute_recall_at_k\n",
        "\n",
        "# recall = 1, recall < 1\n",
        "# from sklearn.datasets import make_spd_matrix\n",
        "# np.random.seed(15)\n",
        "# num_samples=6\n",
        "# D=make_spd_matrix(num_samples)\n",
        "# D=np.abs(D)\n",
        "# for i in range(num_samples):\n",
        "#   D[i,i]=0\n",
        "\n",
        "# test_labels=np.random.randint(0,3,size=num_samples)\n",
        "# test_labels[-1]=1\n",
        "\n",
        "# recall_score=compute_recall_at_k(D,test_labels,k=num_samples)\n",
        "# assert np.allclose(recall_score,1.0)\n",
        "\n",
        "# recall_score=compute_recall_at_k(D,test_labels,k=1)\n",
        "# assert np.allclose(recall_score,1./6)\n",
        "\n",
        "# recall_score=compute_recall_at_k(D,test_labels,k=2)\n",
        "# assert np.allclose(recall_score,2./3)\n",
        "\n",
        "# recall_score=compute_recall_at_k(D,test_labels,k=3)\n",
        "# assert np.allclose(recall_score,2./3)\n",
        "\n",
        "# recall_score=compute_recall_at_k(D,test_labels,k=4)\n",
        "# assert np.allclose(recall_score,1.0)\n",
        "\n",
        "# recall_score=compute_recall_at_k(D,test_labels,k=5)\n",
        "# assert np.allclose(recall_score,1.0)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeAI5PMXQ1-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load model for evaluation\n",
        "model_type='deep'\n",
        "transfer=True\n",
        "freeze_weights=False\n",
        "\n",
        "margin=1.0\n",
        "\n",
        "model_dir=os.path.join(dataset_dir,model_type)\n",
        "if not os.path.isdir(model_dir):\n",
        "  os.mkdir(model_dir)\n",
        "\n",
        "lr=1e-5\n",
        "model=construct_model(model_type,new_input_dim,loss_type,num_classes,transfer,freeze_weights)\n",
        "weights_path=os.path.join(model_dir,'final_%s_%s_transfer_%s_freeze_%s_margin_%s_lr_%s.h5'\n",
        "    %(loss_type,model_type,transfer,freeze_weights,margin,lr))\n",
        "model.load_weights(weights_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5lYZdqEe2K0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "bc07097c-c4e4-4b7e-878a-2ea60415e9c1"
      },
      "source": [
        "# evaluate performance\n",
        "\n",
        "# smaller_test_dataset=test_dataset.take(num_batches_to_take)\n",
        "smaller_test_dataset=test_dataset\n",
        "embeddings_layer_model=models.Model(inputs=model.input,outputs=model.layers[-2].output)\n",
        "predictions=embeddings_layer_model.predict(smaller_test_dataset)\n",
        "\n",
        "# computes pairwise distance between the rows of predictions\n",
        "D=forward(predictions)\n",
        "\n",
        "num_samples=predictions.shape[0]\n",
        "test_labels=[]\n",
        "\n",
        "num_batches=int(1.0*num_samples/BATCH_SIZE)+1\n",
        "for test_image_batch,test_label_batch in smaller_test_dataset.take(num_batches):\n",
        "  test_labels.extend(test_label_batch)\n",
        "test_labels=np.array(test_labels)\n",
        "\n",
        "import time\n",
        "Ks=[1,2,5,10]\n",
        "recall_by_k=[]\n",
        "for k in Ks:\n",
        "  t_start=time.time()\n",
        "  recall_at_k=compute_recall_at_k(D,test_labels,k)\n",
        "  t_end=time.time()\n",
        "  print(\"computing takes \", (t_end-t_start)*1.0/60) \n",
        "  recall_by_k.append(recall_at_k)\n",
        "recall_by_k=np.array(recall_by_k)\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(Ks,recall_by_k,color='r',marker='o')\n",
        "plt.ylabel('Recall@K score (%)')\n",
        "plt.xlabel('K')\n",
        "plt.title('Recall@K score for Resnet50 finetuned on Cifar10')\n",
        "plt.savefig(os.path.join(model_dir,'recall_by_k.png'))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "computing takes  1.4215842803319296\n",
            "computing takes  1.4191080331802368\n",
            "computing takes  1.4198529322942097\n",
            "computing takes  1.4157981475194295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn6KDpWXUZEA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "d8edc298-7c08-42a7-b9d2-8762b3ee5468"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(Ks,recall_by_k,color='r',marker='o')\n",
        "plt.ylabel('Recall@K score (%)')\n",
        "plt.xlabel('K')\n",
        "plt.title('Recall@K score for Resnet50 finetuned on Cifar10')\n",
        "plt.savefig(os.path.join(model_dir,'recall_by_k.png'))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZmZWlBOEmZkV5QRhZmZFOUGYmVlR/x8I73RdSE4RngAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMXCJUW0YrkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}