{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_metric_learning_exp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slala2121/Triplet-net-keras/blob/COS597D/deep_metric_learning_exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaNjSYSpsPV4",
        "colab_type": "text"
      },
      "source": [
        "Code adapted from:\n",
        "https://github.com/KinWaiCheuk/Triplet-net-keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41Rx-qWmmlTw",
        "colab_type": "text"
      },
      "source": [
        "Other relevant links:\n",
        "\n",
        "scratch classification network from https://keras.io/examples/cifar10_resnet/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILvdYoh4ikGN",
        "colab_type": "code",
        "outputId": "2be366c8-34c0-4cfb-f2d6-2181da5317bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dOIE44amJSk",
        "colab_type": "code",
        "outputId": "1aa82a5e-0d5c-4285-abf1-4f1825db166e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install --upgrade tensorflow\n",
        "!pip install tensorflow-addons\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 37kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.4)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 56.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 38.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (42.0.2)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.16.0)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/f8/84b5771faec3eba9fe0c91c8c5896364a8ba08852c0dea5ad2025026dd95/google_auth-1.10.0-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.2.7)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.8)\n",
            "\u001b[31mERROR: tensorboard 2.0.2 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.10.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-auth, tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed google-auth-1.10.0 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/b0/6a1dacc2f4fab422926bfcbab6fa8f08f2a0309d872f3b059340a409b194/tensorflow_addons-0.6.0-cp36-cp36m-manylinux2010_x86_64.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons) (1.12.0)\n",
            "Collecting tensorflow-gpu==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n",
            "\u001b[K     |████████████████████████████████| 380.8MB 44kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.1.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.17.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (3.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (3.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (2.0.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.33.6)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (2.0.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.8.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.11.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0->tensorflow-addons) (42.0.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (1.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (3.1.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (2.21.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0->tensorflow-addons) (2.8.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (4.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (0.2.7)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (1.3.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (3.0.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (3.1.0)\n",
            "Installing collected packages: tensorflow-gpu, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.6.0 tensorflow-gpu-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhYHleWkrVQ9",
        "colab_type": "code",
        "outputId": "dd30dab7-d112-449d-8547-c6ca829f2c9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# current work around for fixing the lifted structure loss file\n",
        "\n",
        "%%writefile /usr/local/lib/python3.6/dist-packages/tensorflow_addons/losses/lifted.py\n",
        "\n",
        "\n",
        "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Implements lifted_struct_loss.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow_addons.losses import metric_learning\n",
        "from tensorflow_addons.utils import keras_utils\n",
        "\n",
        "\n",
        "@keras_utils.register_keras_custom_object\n",
        "@tf.function\n",
        "def lifted_struct_loss(labels, embeddings, margin=1.0):\n",
        "    \"\"\"Computes the lifted structured loss.\n",
        "\n",
        "    Args:\n",
        "      labels: 1-D tf.int32 `Tensor` with shape [batch_size] of\n",
        "        multiclass integer labels.\n",
        "      embeddings: 2-D float `Tensor` of embedding vectors. Embeddings should\n",
        "        not be l2 normalized.\n",
        "      margin: Float, margin term in the loss definition.\n",
        "\n",
        "    Returns:\n",
        "      lifted_loss: tf.float32 scalar.\n",
        "    \"\"\"\n",
        "    # Reshape [batch_size] label tensor to a [batch_size, 1] label tensor.\n",
        "    lshape = tf.shape(labels)\n",
        "    # assert lshape.shape == 1\n",
        "    labels = tf.reshape(labels, [lshape[0], 1])\n",
        "\n",
        "    # Build pairwise squared distance matrix.\n",
        "    pairwise_distances = metric_learning.pairwise_distance(embeddings)\n",
        "\n",
        "    # Build pairwise binary adjacency matrix.\n",
        "    adjacency = tf.math.equal(labels, tf.transpose(labels))\n",
        "    # Invert so we can select negatives only.\n",
        "    adjacency_not = tf.math.logical_not(adjacency)\n",
        "\n",
        "    batch_size = tf.size(labels)\n",
        "\n",
        "    diff = margin - pairwise_distances\n",
        "    mask = tf.cast(adjacency_not, dtype=tf.dtypes.float32)\n",
        "    # Safe maximum: Temporarily shift negative distances\n",
        "    #   above zero before taking max.\n",
        "    #     this is to take the max only among negatives.\n",
        "    row_minimums = tf.math.reduce_min(diff, 1, keepdims=True)\n",
        "    row_negative_maximums = tf.math.reduce_max(\n",
        "        tf.math.multiply(diff - row_minimums, mask), 1,\n",
        "        keepdims=True) + row_minimums\n",
        "\n",
        "    # Compute the loss.\n",
        "    # Keep track of matrix of maximums where M_ij = max(m_i, m_j)\n",
        "    #   where m_i is the max of alpha - negative D_i's.\n",
        "    # This matches the Caffe loss layer implementation at:\n",
        "    #   https://github.com/rksltnl/Caffe-Deep-Metric-Learning-CVPR16/blob/0efd7544a9846f58df923c8b992198ba5c355454/src/caffe/layers/lifted_struct_similarity_softmax_layer.cpp  # pylint: disable=line-too-long\n",
        "\n",
        "    max_elements = tf.math.maximum(row_negative_maximums,\n",
        "                                   tf.transpose(row_negative_maximums))\n",
        "    diff_tiled = tf.tile(diff, [batch_size, 1])\n",
        "    mask_tiled = tf.tile(mask, [batch_size, 1])\n",
        "    max_elements_vect = tf.reshape(tf.transpose(max_elements), [-1, 1])\n",
        "\n",
        "    loss_exp_left = tf.reshape(\n",
        "        tf.math.reduce_sum(\n",
        "            tf.math.multiply(\n",
        "                tf.math.exp(diff_tiled - max_elements_vect), mask_tiled),\n",
        "            1,\n",
        "            keepdims=True), [batch_size, batch_size])\n",
        "\n",
        "    loss_mat = max_elements + tf.math.log(loss_exp_left +\n",
        "                                          tf.transpose(loss_exp_left))\n",
        "    # Add the positive distance.\n",
        "    loss_mat += pairwise_distances\n",
        "\n",
        "    mask_positives = tf.cast(\n",
        "        adjacency, dtype=tf.dtypes.float32) - tf.linalg.diag(\n",
        "            tf.ones([batch_size]))\n",
        "\n",
        "    # *0.5 for upper triangular, and another *0.5 for 1/2 factor for loss^2.\n",
        "    num_positives = tf.math.reduce_sum(mask_positives) / 2.0\n",
        "\n",
        "    lifted_loss = tf.math.truediv(\n",
        "        0.25 * tf.math.reduce_sum(\n",
        "            tf.math.square(\n",
        "                tf.math.maximum(\n",
        "                    tf.math.multiply(loss_mat, mask_positives), 0.0))),\n",
        "        num_positives)\n",
        "    return lifted_loss\n",
        "\n",
        "\n",
        "@keras_utils.register_keras_custom_object\n",
        "class LiftedStructLoss(tf.keras.losses.Loss):\n",
        "    \"\"\"Computes the lifted structured loss.\n",
        "\n",
        "    The loss encourages the positive distances (between a pair of embeddings\n",
        "    with the same labels) to be smaller than any negative distances (between\n",
        "    a pair of embeddings with different labels) in the mini-batch in a way\n",
        "    that is differentiable with respect to the embedding vectors.\n",
        "    See: https://arxiv.org/abs/1511.06452.\n",
        "\n",
        "    Args:\n",
        "      margin: Float, margin term in the loss definition.\n",
        "      name: Optional name for the op.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, margin=1.0, name=None):\n",
        "        super(LiftedStructLoss, self).__init__(\n",
        "            name=name, reduction=tf.keras.losses.Reduction.NONE)\n",
        "        self.margin = margin\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        return lifted_struct_loss(y_true, y_pred, self.margin)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            \"margin\": self.margin,\n",
        "        }\n",
        "        base_config = super(LiftedStructLoss, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /usr/local/lib/python3.6/dist-packages/tensorflow_addons/losses/lifted.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JErGQrxEs22B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u6gowOIiuxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from itertools import permutations\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.optimizers as optimizers\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "\n",
        "source_path=os.path.join('drive','My Drive', 'Colab Notebooks')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "forZgD_0iJQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare dataset either for classification or deep metric learning\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "dataset_name='cifar10'\n",
        "\n",
        "loss_type='lifted'\n",
        "DATA_AUGMENTATIONS=True\n",
        "BATCH_SIZE=32\n",
        "\n",
        "\n",
        "dataset_dir=os.path.join(source_path,dataset_name)\n",
        "if not os.path.isdir(dataset_dir):\n",
        "  os.mkdir(dataset_dir)\n",
        "\n",
        "debug=0\n",
        "\n",
        "if debug:\n",
        "  split_percent=5\n",
        "  train_split = tfds.Split.TRAIN.subsplit(tfds.percent[:split_percent])\n",
        "  test_split = tfds.Split.TEST.subsplit(tfds.percent[:split_percent])\n",
        "  train_dataset,info = tfds.load(name=dataset_name, split=train_split, as_supervised=True, with_info=True)\n",
        "  test_dataset,info = tfds.load(name=dataset_name, split=test_split, as_supervised=True, with_info=True)\n",
        "else:\n",
        "  train_dataset,info = tfds.load(name=dataset_name, split='train', as_supervised=True, with_info=True)\n",
        "  test_dataset,info = tfds.load(name=dataset_name, split='test', as_supervised=True, with_info=True)\n",
        "\n",
        "input_dim=info.features['image'].shape\n",
        "num_classes=info.features['label'].num_classes\n",
        "num_train_images=info.splits['train'].num_examples\n",
        "num_test_images=info.splits['test'].num_examples\n",
        "\n",
        "train_mean_path=os.path.join(dataset_dir,'train_mean.npy')\n",
        "if os.path.exists(train_mean_path):\n",
        "  train_mean=np.load(train_mean_path)\n",
        "else:\n",
        "  train_mean=[]\n",
        "  train_mean=[]\n",
        "  for example in train_dataset.take(num_train_images):\n",
        "    image,label=example[0],example[1]\n",
        "    image=image.numpy().astype('float32')\n",
        "    if len(train_mean)==0:\n",
        "      train_mean=image\n",
        "    else:\n",
        "      train_mean = train_mean+image\n",
        "\n",
        "  train_mean=train_mean*1.0/num_train_images\n",
        "  np.save(train_mean_path,train_mean)\n",
        "\n",
        "# separating the dataset based on classes\n",
        "combined_dataset=train_dataset.concatenate(test_dataset)\n",
        "train_classes=np.arange(num_classes/2)\n",
        "train_dataset=combined_dataset.filter(lambda image,label: label < int(num_classes/2))\n",
        "test_classes=np.arange(num_classes/2,num_classes)\n",
        "test_dataset=combined_dataset.filter(lambda image,label: label >= int(num_classes/2))\n",
        "\n",
        "\n",
        "\n",
        "# preprocessing of labels for classification\n",
        "\n",
        "def _encode_one_hot(img, label):\n",
        "    label = tf.one_hot(label,num_classes)\n",
        "    return (img, label)\n",
        "\n",
        "\n",
        "# Build your input pipelines\n",
        "# preprocessing\n",
        "\n",
        "\n",
        "if loss_type=='classification':\n",
        "  train_dataset = train_dataset.map(_encode_one_hot)\n",
        "  test_dataset = test_dataset.map(_encode_one_hot)\n",
        "\n",
        "\n",
        "train_dataset=train_dataset.map(\n",
        "    lambda image,label: (image-train_mean,label)\n",
        ").map(\n",
        "    lambda image, label: (tf.image.convert_image_dtype(image, tf.float32), label)\n",
        ")\n",
        "\n",
        "test_dataset=test_dataset.map(\n",
        "      lambda image,label: (image-train_mean,label)\n",
        ").map(\n",
        "      lambda image, label: (tf.image.convert_image_dtype(image, tf.float32), label)\n",
        ")\n",
        "\n",
        "\n",
        "if DATA_AUGMENTATIONS:\n",
        "  train_dataset=train_dataset.map(\n",
        "      lambda image, label: (tf.image.random_flip_left_right(image), label)\n",
        "  )\n",
        "\n",
        "new_input_dim=(32,32,3)\n",
        "train_dataset=train_dataset.shuffle(100).batch(BATCH_SIZE)\n",
        "test_dataset=test_dataset.batch(BATCH_SIZE)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZHsKIhMF0wU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare dataset either for classification or deep metric learning\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "dataset_name='caltech_birds2011'\n",
        "\n",
        "loss_type='lifted'\n",
        "DATA_AUGMENTATIONS=True\n",
        "BATCH_SIZE=32\n",
        "\n",
        "debug=1\n",
        "\n",
        "dataset_dir=os.path.join(source_path,dataset_name)\n",
        "if not os.path.isdir(dataset_dir):\n",
        "  os.mkdir(dataset_dir)\n",
        "\n",
        "train_dataset,info = tfds.load(name=dataset_name, split='train',as_supervised=True, with_info=True)\n",
        "test_dataset,info = tfds.load(name=dataset_name, split='test', as_supervised=True, with_info=True)\n",
        "\n",
        "input_dim=info.features['image'].shape\n",
        "num_classes=info.features['label'].num_classes\n",
        "num_train_images=info.splits['train'].num_examples\n",
        "\n",
        "# preprocessing of labels for classification\n",
        "\n",
        "def _encode_one_hot(img, label):\n",
        "    label = tf.one_hot(label,num_classes)\n",
        "    return (img, label)\n",
        "\n",
        "\n",
        "# Build your input pipelines\n",
        "# preprocessing\n",
        "\n",
        "\n",
        "if loss_type=='classification':\n",
        "  train_dataset = train_dataset.map(_encode_one_hot)\n",
        "  test_dataset = test_dataset.map(_encode_one_hot)\n",
        "\n",
        "# resize the data to compute the mean on the original training set\n",
        "train_dataset=train_dataset.map(\n",
        "    lambda image,label: (tf.image.resize(image, [256, 256]),label)\n",
        ")\n",
        "\n",
        "test_dataset=test_dataset.map(\n",
        "    lambda image,label: (tf.image.resize(image, [256, 256]),label)\n",
        ")\n",
        "\n",
        "train_mean_path=os.path.join(dataset_dir,'train_mean.npy')\n",
        "if os.path.exists(train_mean_path):\n",
        "  train_mean=np.load(train_mean_path)\n",
        "else:\n",
        "  train_mean=[]\n",
        "  train_mean=[]\n",
        "  for example in train_dataset.take(num_train_images):\n",
        "    image,label=example[0],example[1]\n",
        "    image=image.numpy().astype('float32')\n",
        "    if len(train_mean)==0:\n",
        "      train_mean=image\n",
        "    else:\n",
        "      train_mean = train_mean+image\n",
        "\n",
        "  train_mean=train_mean*1.0/num_train_images\n",
        "  np.save(train_mean_path,train_mean)\n",
        "\n",
        "# separating the dataset based on classes\n",
        "combined_dataset=train_dataset.concatenate(test_dataset)\n",
        "train_classes=np.arange(100)\n",
        "train_dataset=combined_dataset.filter(lambda image,label: label < 100)\n",
        "test_classes=np.arange(100,200)\n",
        "test_dataset=combined_dataset.filter(lambda image,label: label >= 100)\n",
        "\n",
        "if debug:\n",
        "  train_dataset=train_dataset.take(500)\n",
        "  test_dataset=test_dataset.take(100)\n",
        "\n",
        "train_dataset=train_dataset.map(\n",
        "    lambda image, label: (image-train_mean,label)\n",
        ").map(\n",
        "    lambda image, label: (tf.image.convert_image_dtype(image, tf.float32), label)\n",
        ")\n",
        "\n",
        "test_dataset=test_dataset.map(\n",
        "    lambda image, label: (image-train_mean,label)\n",
        ").map(\n",
        "      lambda image, label: (tf.image.convert_image_dtype(image, tf.float32), label)\n",
        ")\n",
        "\n",
        "\n",
        "if DATA_AUGMENTATIONS:\n",
        "  new_input_dim=(227,227,3)\n",
        "  CROP_SIZE=tf.convert_to_tensor(list(new_input_dim)) \n",
        "  train_dataset=train_dataset.map(\n",
        "      lambda image, label: (tf.image.random_flip_left_right(image), label)\n",
        "  ).map(\n",
        "      lambda image, label: (tf.image.random_crop(image,CROP_SIZE), label)\n",
        "  )\n",
        "\n",
        "  test_dataset=test_dataset.map(\n",
        "      lambda image,label: (tf.image.random_crop(image,CROP_SIZE), label)\n",
        "  )\n",
        "\n",
        "train_dataset=train_dataset.shuffle(100).batch(BATCH_SIZE)\n",
        "test_dataset=test_dataset.shuffle(100).batch(BATCH_SIZE)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ed4cf908-229e-48ec-f7a9-2bf731744599",
        "id": "203WSdOnF3XS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        }
      },
      "source": [
        "image,label=next(iter(train_dataset))\n",
        "# print(label)\n",
        "plt.figure()\n",
        "plt.imshow(image[0])\n",
        "\n",
        "image,label=next(iter(test_dataset))\n",
        "# print(label)\n",
        "plt.figure()\n",
        "plt.imshow(image[0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([4 3 3 3 4 1 3 0 0 3 2 0 1 2 0 4 4 3 0 1 4 4 2 2 1 2 2 3 0 1 0 4], shape=(32,), dtype=int64)\n",
            "tf.Tensor([9 7 9 6 9 7 5 9 6 9 8 6 8 5 6 8 7 5 5 7 5 9 6 6 5 6 6 8 5 5 8 9], shape=(32,), dtype=int64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbf9e048b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/j8C1XqoC6PSOQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk_djf8anBK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "\n",
        "# based on the lifted scheme paper\n",
        "def create_deep_base_network(input_dim,loss_type,num_classes=0,transfer=False,freeze_weights=False):\n",
        "  weights='imagenet' if transfer else None\n",
        "  conv_base = ResNet50(weights=weights, include_top=False, input_shape=input_dim)\n",
        "\n",
        "  if freeze_weights:\n",
        "    for layer in conv_base.layers:\n",
        "      layer.trainable=False\n",
        "  \n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Input(input_dim))\n",
        "  model.add(conv_base)\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.BatchNormalization())\n",
        "\n",
        "  if loss_type=='classification':\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "  else:\n",
        "    model.add(layers.Dense(64, activation=None))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def create_shallow_network(input_dim,loss_type,num_classes=0):\n",
        "  model=tf.keras.Sequential()\n",
        "  model.add(layers.Input(input_dim))\n",
        "  model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=5, padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=2, padding='same'))\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  if loss_type=='classification':\n",
        "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Dense(num_classes,activation='softmax'))\n",
        "  else:\n",
        "    model.add(tf.keras.layers.Dense(256, activation=None))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "  return model\n",
        "\n",
        "def construct_model(model_type,input_dim,loss_type,num_classes,transfer=False,freeze_weights=False):\n",
        "  if model_type=='shallow':\n",
        "    model=create_shallow_network(input_dim,loss_type,num_classes)\n",
        "  elif model_type=='deep':\n",
        "    model=create_deep_base_network(input_dim,loss_type,num_classes,transfer,freeze_weights)\n",
        "\n",
        "  if loss_type =='triplet':\n",
        "    model.add(tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)))\n",
        "  return model\n",
        "\n",
        "def construct_loss(loss_type,margin):\n",
        "  if loss_type=='triplet':\n",
        "    loss=tfa.losses.TripletSemiHardLoss(margin=margin)\n",
        "  elif loss_type=='lifted':\n",
        "    loss=tfa.losses.LiftedStructLoss(margin=margin)\n",
        "  elif loss_type=='classification':\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy()\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlxiWw0svGrf",
        "colab_type": "code",
        "outputId": "dc9f59a3-5100-482f-9cab-efddc90d14bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# tune lr\n",
        "\n",
        "lrs=[1e-2,1e-3,1e-4,1e-5,1e-6]\n",
        "# lrs=[1e-6]\n",
        "model_type='deep'\n",
        "transfer=True\n",
        "freeze_weights=False\n",
        "\n",
        "margin=1.0\n",
        "\n",
        "model_dir=os.path.join(dataset_dir,model_type)\n",
        "if not os.path.isdir(model_dir):\n",
        "  os.mkdir(model_dir)\n",
        "\n",
        "num_epochs=30\n",
        "\n",
        "fig,ax=plt.subplots(2,3)\n",
        "ax=ax.ravel()\n",
        "for lr_index,lr in enumerate(lrs):\n",
        "  model=construct_model(model_type,new_input_dim,loss_type,num_classes,transfer,freeze_weights)\n",
        "  loss=construct_loss(loss_type,margin)\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(lr),loss=loss)\n",
        "\n",
        "  history = model.fit(\n",
        "      train_dataset,\n",
        "      epochs=num_epochs)\n",
        "\n",
        "  ax[lr_index].set_title('Loss for lr_%s'%(str(lr)))\n",
        "  ax[lr_index].plot(np.arange(num_epochs),history.history['loss'],'r',label='train_loss_lr_%s'%(str(lr)))\n",
        "  \n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(model_dir,'loss_plot_lr_tune_%s_transfer_%s_freeze_%s_%s_%s.png'%(model_type,transfer,freeze_weights,loss_type,margin)))\n",
        "plt.close()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "50/50 [==============================] - 10s 206ms/step - loss: 10.2924\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.8001\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.8982\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.8379\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.7307\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.8476\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.7460\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.8094\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 6.8544\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: nan\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.8031\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 6.8181\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 2s 50ms/step - loss: 6.7757\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 6.7375\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 6.8040\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.7976\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 6.8952\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.7837\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.7965\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.7968\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 6.8634\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.8399\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 6.8215\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.7091\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.8678\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.7759\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 6.9303\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 6.9048\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 6.8557\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.8242\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 11s 212ms/step - loss: 30.0034\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 38.9014\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 35.6655\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 35.2073\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 34.2411\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 65.2296\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 50.9228\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 43.0813\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 35.0887\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 25.6663\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 26.0485\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 53.8815\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 54.8821\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 32.7651\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 27.9822\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 22.4869\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 17.6472\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 21.1577\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 18.9658\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 15.0561\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 14.5517\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 20.4349\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 17.8200\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 15.6104\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 14.2218\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 24.7379\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 52.4114\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 6.8412\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.8183\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 6.8828\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 9s 182ms/step - loss: 25.1138\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 25.3639\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 19.8209\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 2s 50ms/step - loss: 21.9981\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 23.0149\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 21.5488\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 17.9106\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 19.0524\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 18.7438\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 17.5621\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 20.5515\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 18.8129\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 19.1044\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 17.6176\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 16.2980\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 15.5585\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 16.9160\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 16.3992\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 17.3732\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 16.4212\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 14.5553\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 16.1443\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 14.3678\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 15.4467\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 15.1637\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 15.0388\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: nan\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 6.8722\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.7795\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 6.8497\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 9s 187ms/step - loss: 25.6061\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 26.0982\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 26.3953\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 28.7258\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 25.7184\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 25.8706\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 23.1755\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 23.3399\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 24.1381\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 25.5103\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 26.0503\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 25.6325\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 24.0735\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 23.6174\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 24.3102\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 23.7824\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 22.7997\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 18.6610\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 24.1850\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 2s 49ms/step - loss: 21.4786\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 2s 50ms/step - loss: 24.3453\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 20.2368\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 20.9795\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 21.9011\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 22.5933\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 20.8697\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 22.4196\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 22.0144\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 22.9311\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 24.0592\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 22.2241\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 25.7509\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 26.5906\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 25.9804\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 22.9246\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 25.5734\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 26.4356\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 23.7530\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 25.0053\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 27.4133\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 24.8672\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 23.7806\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 24.6833\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 25.7714\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 25.6685\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 26.2583\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 26.6122\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 26.3344\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 29.2412\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 24.3001\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 26.2700\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 28.2294\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 2s 50ms/step - loss: 24.4351\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 24.7398\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 26.4218\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 28.2207\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 23.0186\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 28.6461\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 2s 49ms/step - loss: 25.2192\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 27.8505\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E19n3qkFVyc4",
        "colab_type": "code",
        "outputId": "bd2c3e68-909b-4bab-8c01-f7e963d54f0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "# train model\n",
        "\n",
        "lr=1e-5\n",
        "\n",
        "model_type='deep'\n",
        "transfer=True\n",
        "freeze_weights=False\n",
        "\n",
        "margin=1.0\n",
        "\n",
        "model_dir=os.path.join(dataset_dir,model_type)\n",
        "if not os.path.isdir(model_dir):\n",
        "  os.mkdir(model_dir)\n",
        "\n",
        "num_epochs=50\n",
        "\n",
        "model=construct_model(model_type,new_input_dim,loss_type,num_classes,transfer,freeze_weights)\n",
        "loss=construct_loss(loss_type,margin)\n",
        "\n",
        "# Compile the model\n",
        "metrics=[]\n",
        "if loss_type=='classification':\n",
        "  metrics=['accuracy']\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr),loss=loss,metrics=metrics)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "filepath=os.path.join(model_dir,'final_%s_%s_transfer_%s_freeze_%s_margin_%s_lr_%s.h5'\n",
        "    %(loss_type,model_type,transfer,freeze_weights,margin,lr))\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_loss',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "callbacks = [checkpoint]\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=test_dataset,\n",
        "    callbacks=callbacks)\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(num_epochs),history.history['loss'],'r',label='train_loss')\n",
        "plt.plot(np.arange(num_epochs),history.history['val_loss'],'b',label='val_loss')\n",
        "plt.legend()\n",
        "filepath=os.path.join(model_dir,'final_loss_plot_%s_%s_transfer_%s_freeze_%s_margin_%s_lr_%s.png'\n",
        "%(loss_type,model_type,transfer,freeze_weights,margin,lr))\n",
        "plt.savefig(filepath)\n",
        "plt.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "    938/Unknown - 53s 56ms/step - loss: 33.0522\n",
            "Epoch 00001: val_loss improved from inf to 63.63127, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 69s 74ms/step - loss: 33.0522 - val_loss: 0.0000e+00\n",
            "Epoch 2/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 27.0677\n",
            "Epoch 00002: val_loss improved from 63.63127 to 28.13180, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 64s 68ms/step - loss: 27.0677 - val_loss: 28.1318\n",
            "Epoch 3/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 25.4328\n",
            "Epoch 00003: val_loss improved from 28.13180 to 25.18558, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 66s 70ms/step - loss: 25.4328 - val_loss: 25.1856\n",
            "Epoch 4/50\n",
            "936/938 [============================>.] - ETA: 0s - loss: 24.1200\n",
            "Epoch 00004: val_loss improved from 25.18558 to 22.76600, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 64s 68ms/step - loss: 24.1186 - val_loss: 22.7660\n",
            "Epoch 5/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 23.3777\n",
            "Epoch 00005: val_loss improved from 22.76600 to 21.77829, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_lifted_deep_transfer_True_freeze_False_margin_1.0_lr_1e-05.h5\n",
            "938/938 [==============================] - 64s 68ms/step - loss: 23.3777 - val_loss: 21.7783\n",
            "Epoch 6/50\n",
            " 18/938 [..............................] - ETA: 55s - loss: 22.8099"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-uo2QKnMRkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate performance of model using Recall@K\n",
        "\n",
        "# retrieve k nearest neighbors based on embeddings\n",
        "\n",
        "\n",
        "# pairwise distance matrix computation: \n",
        "# https://stackoverflow.com/questions/37009647/compute-pairwise-distance-in-a-batch-without-replicating-tensor-in-tensorflow\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def forward(A):\n",
        "  r = tf.reduce_sum(A*A, 1)\n",
        "  r = tf.reshape(r, [-1, 1])\n",
        "  D = r - 2*tf.matmul(A, tf.transpose(A)) + tf.transpose(r)\n",
        "  return D\n",
        "# A = tf.constant([[1, 1], [2, 2], [3, 3]])\n",
        "# res=forward(A)\n",
        "# print(res)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "D: 2d array num_samplesxnum_samples (num_samples >=2)\n",
        "test_labels: 1d array num_samples\n",
        "k: int # nearest neighbors >=1\n",
        "\"\"\"\n",
        "def compute_recall_at_k(D,test_labels,k):\n",
        "  num_samples=D.shape[0]\n",
        "  recall=0\n",
        "\n",
        "  for sample_index in range(num_samples):\n",
        "    ind_samples_sorted_by_distance=np.argsort(D[sample_index])\n",
        "    # assert ind_samples_sorted_by_distance[0]==sample_index\n",
        "    ind_samples_sorted_by_distance=ind_samples_sorted_by_distance[1:]# exclude the sample in question\n",
        "    \n",
        "    ind_nearest_k_neighbors=ind_samples_sorted_by_distance[:k]\n",
        "    labels_nearest_k_neighbors=test_labels[ind_nearest_k_neighbors]\n",
        "    true_label=test_labels[sample_index]\n",
        "\n",
        "    if true_label in labels_nearest_k_neighbors:\n",
        "      recall+=1\n",
        "\n",
        "  recall*=(1.0/num_samples)\n",
        "\n",
        "  return recall\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# test compute_recall_at_k\n",
        "\n",
        "# recall = 1, recall < 1\n",
        "from sklearn.datasets import make_spd_matrix\n",
        "np.random.seed(15)\n",
        "num_samples=6\n",
        "D=make_spd_matrix(num_samples)\n",
        "D=np.abs(D)\n",
        "for i in range(num_samples):\n",
        "  D[i,i]=0\n",
        "\n",
        "test_labels=np.random.randint(0,3,size=num_samples)\n",
        "test_labels[-1]=1\n",
        "\n",
        "recall_score=compute_recall_at_k(D,test_labels,k=num_samples)\n",
        "assert np.allclose(recall_score,1.0)\n",
        "\n",
        "recall_score=compute_recall_at_k(D,test_labels,k=1)\n",
        "assert np.allclose(recall_score,1./6)\n",
        "\n",
        "recall_score=compute_recall_at_k(D,test_labels,k=2)\n",
        "assert np.allclose(recall_score,2./3)\n",
        "\n",
        "recall_score=compute_recall_at_k(D,test_labels,k=3)\n",
        "assert np.allclose(recall_score,2./3)\n",
        "\n",
        "recall_score=compute_recall_at_k(D,test_labels,k=4)\n",
        "assert np.allclose(recall_score,1.0)\n",
        "\n",
        "recall_score=compute_recall_at_k(D,test_labels,k=5)\n",
        "assert np.allclose(recall_score,1.0)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5lYZdqEe2K0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "592f037f-513e-4f92-befa-ad8b309ac389"
      },
      "source": [
        "# evaluate performance\n",
        "\n",
        "embeddings_layer_model=models.Model(inputs=model.input,outputs=model.layers[-4].output)\n",
        "predictions=embeddings_layer_model.predict(test_dataset)\n",
        "\n",
        "# computes pairwise distance between the rows of predictions\n",
        "D=forward(predictions)\n",
        "num_test_samples=D.shape[0]\n",
        "\n",
        "Ks=[]\n",
        "recall_by_k=[]\n",
        "for k in Ks:\n",
        "  recall_at_k=compute_recall_at_k(D,test_labels,k) \n",
        "  recall_by_k.append(recall_at_k)\n",
        "recall_by_k=np.array(recall_by_k)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-1fa3067649d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membeddings_layer_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membeddings_layer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# computes pairwise distance between the rows of predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UGVSb0sXVV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}