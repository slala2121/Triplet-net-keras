{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_metric_learning_exp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slala2121/Triplet-net-keras/blob/COS597D/deep_metric_learning_exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaNjSYSpsPV4",
        "colab_type": "text"
      },
      "source": [
        "Code adapted from:\n",
        "https://github.com/KinWaiCheuk/Triplet-net-keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41Rx-qWmmlTw",
        "colab_type": "text"
      },
      "source": [
        "Other relevant links:\n",
        "\n",
        "scratch classification network from https://keras.io/examples/cifar10_resnet/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dOIE44amJSk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dab07961-ff9d-4b36-f816-874811f23402"
      },
      "source": [
        "!pip install --upgrade tensorflow\n",
        "!pip install tensorflow-addons\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (1.10.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (42.0.2)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.2.7)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: tensorflow-gpu==2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons) (2.0.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons) (1.12.0)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (2.0.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.11.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (3.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (3.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (2.0.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.8.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.1.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.17.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.33.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (0.16.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (1.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (3.1.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (0.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (42.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (2.21.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0->tensorflow-addons) (2.8.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (0.2.7)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (4.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (1.3.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (3.0.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILvdYoh4ikGN",
        "colab_type": "code",
        "outputId": "2aea1c6e-c0d8-42b6-ae8f-96e87ee2205f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u6gowOIiuxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from itertools import permutations\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.optimizers as optimizers\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "\n",
        "source_path=os.path.join('drive','My Drive', 'Colab Notebooks')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "forZgD_0iJQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare dataset either for classification or deep metric learning\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "dataset_name='cifar10'\n",
        "\n",
        "dataset_dir=os.path.join(source_path,dataset_name)\n",
        "if not os.path.isdir(dataset_dir):\n",
        "  os.mkdir(dataset_dir)\n",
        "\n",
        "debug=1\n",
        "\n",
        "if debug:\n",
        "  split_percent=1\n",
        "  train_split = tfds.Split.TRAIN.subsplit(tfds.percent[:split_percent])\n",
        "  test_split = tfds.Split.TEST.subsplit(tfds.percent[:split_percent])\n",
        "  train_dataset,info = tfds.load(name=dataset_name, split=train_split, as_supervised=True, with_info=True)\n",
        "  test_dataset,info = tfds.load(name=dataset_name, split=test_split, as_supervised=True, with_info=True)\n",
        "else:\n",
        "  train_dataset,info = tfds.load(name=dataset_name, split='train', as_supervised=True, with_info=True)\n",
        "  test_dataset,info = tfds.load(name=dataset_name, split='test', as_supervised=True, with_info=True)\n",
        "\n",
        "input_dim=info.features['image'].shape\n",
        "num_classes=info.features['label'].num_classes\n",
        "\n",
        "train_mean_path=os.path.join(dataset_dir,'train_mean.npy')\n",
        "if os.path.exists(train_mean_path):\n",
        "  train_mean=np.load(train_mean_path)\n",
        "else:\n",
        "  train_mean=[]\n",
        "  num_train_images=info.splits['train'].num_examples\n",
        "  train_mean=[]\n",
        "  for example in train_dataset.take(num_train_images):\n",
        "    image,label=example[0],example[1]\n",
        "    image=image.numpy().astype('float32')\n",
        "    if len(train_mean)==0:\n",
        "      train_mean=image\n",
        "    else:\n",
        "      train_mean = train_mean+image\n",
        "\n",
        "  train_mean=train_mean*1.0/num_train_images\n",
        "  np.save(train_mean_path,train_mean)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ug1PiOKC9EY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare dataset either for classification or deep metric learning\n",
        "\n",
        "def _normalize_img(img, label):\n",
        "    img = img - train_mean\n",
        "    img = tf.cast(img, tf.float32) / 255.\n",
        "    return (img, label)\n",
        "\n",
        "\n",
        "# preprocessing of labels for classification\n",
        "\n",
        "def _encode_one_hot(img, label):\n",
        "    label = tf.one_hot(label,num_classes)\n",
        "    return (img, label)\n",
        "\n",
        "\n",
        "train_dataset = train_dataset.map(_normalize_img)\n",
        "test_dataset = test_dataset.map(_normalize_img)\n",
        "\n",
        "loss_type='triplet'\n",
        "if loss_type=='classification':\n",
        "  train_dataset = train_dataset.map(_encode_one_hot)\n",
        "  test_dataset = test_dataset.map(_encode_one_hot)\n",
        "\n",
        "# Build your input pipelines\n",
        "\n",
        "train_dataset = train_dataset.shuffle(1024).batch(32)\n",
        "test_dataset = test_dataset.batch(32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk_djf8anBK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "\n",
        "# based on the lifted scheme paper\n",
        "def create_deep_base_network(input_dim,loss_type,num_classes=0,transfer=False,freeze_weights=False):\n",
        "  weights='imagenet' if transfer else None\n",
        "  conv_base = ResNet50(weights=weights, include_top=False, input_shape=input_dim)\n",
        "\n",
        "  if freeze_weights:\n",
        "    for layer in conv_base.layers:\n",
        "      layer.trainable=False\n",
        "  \n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Input(input_dim))\n",
        "  model.add(conv_base)\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.BatchNormalization())\n",
        "\n",
        "  if loss_type=='classification':\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "  else:\n",
        "    model.add(layers.Dense(64, activation=None))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def create_shallow_network(input_dim,loss_type,num_classes=0):\n",
        "  model=tf.keras.Sequential()\n",
        "  model.add(layers.Input(input_dim))\n",
        "  model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=5, padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "  model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=2, padding='same'))\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  if loss_type=='classification':\n",
        "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers(Dense(num_classes,activation='softmax')))\n",
        "  else:\n",
        "    model.add(tf.keras.layers.Dense(256, activation=None))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "  return model\n",
        "\n",
        "def construct_model(model_type,input_dim,loss_type,num_classes,transfer=False,freeze_weights=False):\n",
        "  if model_type=='shallow':\n",
        "    model=create_shallow_network(input_dim,loss_type,num_classes)\n",
        "  elif model_type=='deep':\n",
        "    model=create_deep_base_network(input_dim,loss_type,num_classes,transfer,freeze_weights)\n",
        "\n",
        "  if loss_type =='triplet':\n",
        "    model.add(tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)))\n",
        "  return model\n",
        "\n",
        "def construct_loss(loss_type,margin):\n",
        "  if loss_type=='triplet':\n",
        "    loss=tfa.losses.TripletSemiHardLoss(margin=margin)\n",
        "  elif loss_type=='lifted':\n",
        "    loss=tfa.losses.LiftedStructLoss(margin=margin)\n",
        "  elif loss_type=='classification':\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy()\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlxiWw0svGrf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7109a39b-ac91-45aa-b7e6-1df199102c74"
      },
      "source": [
        "# tune lr\n",
        "\n",
        "lrs=[1e-1,1e-2,1e-3,1e-4,1e-5]\n",
        "\n",
        "model_type='deep'\n",
        "transfer=True\n",
        "freeze_weights=False\n",
        "\n",
        "margin=1.0\n",
        "\n",
        "model_dir=os.path.join(dataset_dir,model_type)\n",
        "if not os.path.isdir(model_dir):\n",
        "  os.mkdir(model_dir)\n",
        "\n",
        "num_epochs=30\n",
        "\n",
        "fig,ax=plt.subplots(2,3)\n",
        "ax=ax.ravel()\n",
        "for lr_index,lr in enumerate(lrs):\n",
        "\n",
        "  model=construct_model(model_type,input_dim,loss_type,num_classes,transfer,freeze_weights)\n",
        "  loss=construct_loss(loss_type,margin)\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(lr),loss=loss)\n",
        "\n",
        "  history = model.fit(\n",
        "      train_dataset,\n",
        "      epochs=num_epochs)\n",
        "\n",
        "  ax[lr_index].set_title('Loss for lr_%s'%(str(lr)))\n",
        "  ax[lr_index].plot(np.arange(num_epochs),history.history['loss'],'r',label='train_loss_lr_%s'%(str(lr)))\n",
        "  \n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(model_dir,'loss_plot_lr_tune_%s_transfer_%s_freeze_%s_%s_%s.png'%(model_type,transfer,freeze_weights,loss_type,margin)))\n",
        "plt.close()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "16/16 [==============================] - 9s 589ms/step - loss: 0.9433\n",
            "Epoch 2/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9444\n",
            "Epoch 3/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9243\n",
            "Epoch 4/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.9160\n",
            "Epoch 5/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.9134\n",
            "Epoch 6/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.9122\n",
            "Epoch 7/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9082\n",
            "Epoch 8/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.9026\n",
            "Epoch 9/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.8967\n",
            "Epoch 10/30\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.9393\n",
            "Epoch 11/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9532\n",
            "Epoch 12/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.9403\n",
            "Epoch 13/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9226\n",
            "Epoch 14/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.8896\n",
            "Epoch 15/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.8923\n",
            "Epoch 16/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.8947\n",
            "Epoch 17/30\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.8801\n",
            "Epoch 18/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.8802\n",
            "Epoch 19/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.8737\n",
            "Epoch 20/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.8899\n",
            "Epoch 21/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.8860\n",
            "Epoch 22/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.8828\n",
            "Epoch 23/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.8888\n",
            "Epoch 24/30\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.8932\n",
            "Epoch 25/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.8897\n",
            "Epoch 26/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.8982\n",
            "Epoch 27/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.8961\n",
            "Epoch 28/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.8732\n",
            "Epoch 29/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.8841\n",
            "Epoch 30/30\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.8854\n",
            "Epoch 1/30\n",
            "16/16 [==============================] - 10s 611ms/step - loss: 0.9260\n",
            "Epoch 2/30\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.9134\n",
            "Epoch 3/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9117\n",
            "Epoch 4/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9060\n",
            "Epoch 5/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9122\n",
            "Epoch 6/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9081\n",
            "Epoch 7/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.9094\n",
            "Epoch 8/30\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.9112\n",
            "Epoch 9/30\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.9140\n",
            "Epoch 10/30\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.8942\n",
            "Epoch 11/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.9052\n",
            "Epoch 12/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9018\n",
            "Epoch 13/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9054\n",
            "Epoch 14/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.8973\n",
            "Epoch 15/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9014\n",
            "Epoch 16/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9032\n",
            "Epoch 17/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.9050\n",
            "Epoch 18/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9087\n",
            "Epoch 19/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9189\n",
            "Epoch 20/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.8967\n",
            "Epoch 21/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.8942\n",
            "Epoch 22/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9107\n",
            "Epoch 23/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.8874\n",
            "Epoch 24/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9036\n",
            "Epoch 25/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.8959\n",
            "Epoch 26/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9028\n",
            "Epoch 27/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.8965\n",
            "Epoch 28/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9120\n",
            "Epoch 29/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9057\n",
            "Epoch 30/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.8998\n",
            "Epoch 1/30\n",
            "16/16 [==============================] - 10s 617ms/step - loss: 0.9594\n",
            "Epoch 2/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.9543\n",
            "Epoch 3/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9348\n",
            "Epoch 4/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9337\n",
            "Epoch 5/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9254\n",
            "Epoch 6/30\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.9145\n",
            "Epoch 7/30\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.9085\n",
            "Epoch 8/30\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.9146\n",
            "Epoch 9/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9062\n",
            "Epoch 10/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9037\n",
            "Epoch 11/30\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.9005\n",
            "Epoch 12/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9089\n",
            "Epoch 13/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.8902\n",
            "Epoch 14/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.8800\n",
            "Epoch 15/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.8893\n",
            "Epoch 16/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.8989\n",
            "Epoch 17/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.8919\n",
            "Epoch 18/30\n",
            "16/16 [==============================] - 2s 111ms/step - loss: 0.8995\n",
            "Epoch 19/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.8772\n",
            "Epoch 20/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.8783\n",
            "Epoch 21/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.8775\n",
            "Epoch 22/30\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.8669\n",
            "Epoch 23/30\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.8716\n",
            "Epoch 24/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.8869\n",
            "Epoch 25/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.8801\n",
            "Epoch 26/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.8918\n",
            "Epoch 27/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.8877\n",
            "Epoch 28/30\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.8967\n",
            "Epoch 29/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9084\n",
            "Epoch 30/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9044\n",
            "Epoch 1/30\n",
            "16/16 [==============================] - 9s 539ms/step - loss: 0.9632\n",
            "Epoch 2/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9639\n",
            "Epoch 3/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9640\n",
            "Epoch 4/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9624\n",
            "Epoch 5/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9569\n",
            "Epoch 6/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.9557\n",
            "Epoch 7/30\n",
            "16/16 [==============================] - 2s 111ms/step - loss: 0.9554\n",
            "Epoch 8/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9459\n",
            "Epoch 9/30\n",
            "16/16 [==============================] - 2s 111ms/step - loss: 0.9439\n",
            "Epoch 10/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.9397\n",
            "Epoch 11/30\n",
            "16/16 [==============================] - 2s 111ms/step - loss: 0.9343\n",
            "Epoch 12/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.9352\n",
            "Epoch 13/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9338\n",
            "Epoch 14/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.9295\n",
            "Epoch 15/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.9236\n",
            "Epoch 16/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9138\n",
            "Epoch 17/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9184\n",
            "Epoch 18/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.9148\n",
            "Epoch 19/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9091\n",
            "Epoch 20/30\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.9092\n",
            "Epoch 21/30\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.9050\n",
            "Epoch 22/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.9006\n",
            "Epoch 23/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.8954\n",
            "Epoch 24/30\n",
            "16/16 [==============================] - 2s 111ms/step - loss: 0.9000\n",
            "Epoch 25/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.8936\n",
            "Epoch 26/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.8989\n",
            "Epoch 27/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.9002\n",
            "Epoch 28/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.8810\n",
            "Epoch 29/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.8902\n",
            "Epoch 30/30\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.8908\n",
            "Epoch 1/30\n",
            "16/16 [==============================] - 9s 541ms/step - loss: 0.9673\n",
            "Epoch 2/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9664\n",
            "Epoch 3/30\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.9682\n",
            "Epoch 4/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9667\n",
            "Epoch 5/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9650\n",
            "Epoch 6/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.9673\n",
            "Epoch 7/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9657\n",
            "Epoch 8/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9655\n",
            "Epoch 9/30\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.9657\n",
            "Epoch 10/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.9634\n",
            "Epoch 11/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9651\n",
            "Epoch 12/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9684\n",
            "Epoch 13/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.9659\n",
            "Epoch 14/30\n",
            "16/16 [==============================] - 2s 111ms/step - loss: 0.9669\n",
            "Epoch 15/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9699\n",
            "Epoch 16/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9654\n",
            "Epoch 17/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9635\n",
            "Epoch 18/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.9665\n",
            "Epoch 19/30\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.9637\n",
            "Epoch 20/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9650\n",
            "Epoch 21/30\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.9661\n",
            "Epoch 22/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9663\n",
            "Epoch 23/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9641\n",
            "Epoch 24/30\n",
            "16/16 [==============================] - 2s 116ms/step - loss: 0.9623\n",
            "Epoch 25/30\n",
            "16/16 [==============================] - 2s 111ms/step - loss: 0.9632\n",
            "Epoch 26/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9651\n",
            "Epoch 27/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.9622\n",
            "Epoch 28/30\n",
            "16/16 [==============================] - 2s 114ms/step - loss: 0.9605\n",
            "Epoch 29/30\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.9645\n",
            "Epoch 30/30\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.9640\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E19n3qkFVyc4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9b8d3319-e7c9-4bfd-d20c-d188427ae9e6"
      },
      "source": [
        "# train model\n",
        "\n",
        "lr=1e-4\n",
        "\n",
        "model_type='deep'\n",
        "transfer=True\n",
        "freeze_weights=False\n",
        "\n",
        "margin=1.0\n",
        "\n",
        "model_dir=os.path.join(dataset_dir,model_type)\n",
        "if not os.path.isdir(model_dir):\n",
        "  os.mkdir(model_dir)\n",
        "\n",
        "num_epochs=30\n",
        "\n",
        "model=construct_model(model_type,input_dim,loss_type,num_classes,transfer,freeze_weights)\n",
        "loss=construct_loss(loss_type,margin)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr),loss=loss)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "filepath=os.path.join(model_dir,'final_%s_%s_transfer_%s_freeze_%s_%s_%s.h5'%(loss_type,model_type,transfer,freeze_weights,margin))\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_loss',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "callbacks = [checkpoint]\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=test_dataset,\n",
        "    callbacks=callbacks)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(num_epochs),history.history['loss'],'r',label='train_loss')\n",
        "plt.plot(np.arange(num_epochs),history.history['val_loss'],'b',label='val_loss')\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(model_dir,'final_loss_plot%s_transfer_%s_freeze_%s_%s_%s.png'%(model_type,transfer,freeze_weights,loss_type,margin)))\n",
        "plt.close()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "     16/Unknown - 9s 590ms/step - loss: 2.8915\n",
            "Epoch 00001: val_loss improved from inf to 3.50534, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_deep_transfer_True_freeze_False_classification_1.0.h5\n",
            "16/16 [==============================] - 12s 767ms/step - loss: 2.8915 - val_loss: 0.0000e+00\n",
            "Epoch 2/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 2.7934\n",
            "Epoch 00002: val_loss did not improve from 3.50534\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 2.6828 - val_loss: 3.6797\n",
            "Epoch 3/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 2.6248\n",
            "Epoch 00003: val_loss did not improve from 3.50534\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 2.5172 - val_loss: 4.4345\n",
            "Epoch 4/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 2.1333\n",
            "Epoch 00004: val_loss did not improve from 3.50534\n",
            "16/16 [==============================] - 2s 141ms/step - loss: 2.1864 - val_loss: 4.4976\n",
            "Epoch 5/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.8845\n",
            "Epoch 00005: val_loss did not improve from 3.50534\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 1.9998 - val_loss: 5.1502\n",
            "Epoch 6/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.8719\n",
            "Epoch 00006: val_loss did not improve from 3.50534\n",
            "16/16 [==============================] - 2s 148ms/step - loss: 1.8687 - val_loss: 5.3994\n",
            "Epoch 7/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.9231\n",
            "Epoch 00007: val_loss did not improve from 3.50534\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 1.8606 - val_loss: 4.9247\n",
            "Epoch 8/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.5795\n",
            "Epoch 00008: val_loss did not improve from 3.50534\n",
            "16/16 [==============================] - 2s 138ms/step - loss: 1.6842 - val_loss: 3.8299\n",
            "Epoch 9/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.7235\n",
            "Epoch 00009: val_loss improved from 3.50534 to 3.49944, saving model to drive/My Drive/Colab Notebooks/cifar10/deep/final_deep_transfer_True_freeze_False_classification_1.0.h5\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.6218 - val_loss: 3.4994\n",
            "Epoch 10/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.5586\n",
            "Epoch 00010: val_loss did not improve from 3.49944\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 1.5030 - val_loss: 4.1350\n",
            "Epoch 11/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.4250\n",
            "Epoch 00011: val_loss did not improve from 3.49944\n",
            "16/16 [==============================] - 2s 144ms/step - loss: 1.3771 - val_loss: 4.3718\n",
            "Epoch 12/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.4875\n",
            "Epoch 00012: val_loss did not improve from 3.49944\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 1.3247 - val_loss: 4.9638\n",
            "Epoch 13/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.2748\n",
            "Epoch 00013: val_loss did not improve from 3.49944\n",
            "16/16 [==============================] - 2s 149ms/step - loss: 1.2488 - val_loss: 7.9016\n",
            "Epoch 14/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.1040\n",
            "Epoch 00014: val_loss did not improve from 3.49944\n",
            "16/16 [==============================] - 3s 158ms/step - loss: 1.1654 - val_loss: 10.3808\n",
            "Epoch 15/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.8621\n",
            "Epoch 00015: val_loss did not improve from 3.49944\n",
            "16/16 [==============================] - 2s 147ms/step - loss: 1.0123 - val_loss: 10.3250\n",
            "Epoch 16/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.1161\n",
            "Epoch 00016: val_loss did not improve from 3.49944\n",
            "16/16 [==============================] - 2s 143ms/step - loss: 1.0231 - val_loss: 11.6279\n",
            "Epoch 17/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.9507\n",
            "Epoch 00017: val_loss did not improve from 3.49944\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.9613 - val_loss: 12.0408\n",
            "Epoch 18/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.7986\n",
            "Epoch 00018: val_loss did not improve from 3.49944\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.8698 - val_loss: 12.8295\n",
            "Epoch 19/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.7379\n",
            "Epoch 00019: val_loss did not improve from 3.49944\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.8283 - val_loss: 9.9610\n",
            "Epoch 20/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.7048\n",
            "Epoch 00020: val_loss did not improve from 3.49944\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.7310 - val_loss: 9.5368\n",
            "Epoch 21/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.6368\n",
            "Epoch 00021: val_loss did not improve from 3.49944\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.6994 - val_loss: 10.4904\n",
            "Epoch 22/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.5991\n",
            "Epoch 00022: val_loss did not improve from 3.49944\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.6586 - val_loss: 12.1441\n",
            "Epoch 23/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.6875\n",
            "Epoch 00023: val_loss did not improve from 3.49944\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.6544 - val_loss: 13.8281\n",
            "Epoch 24/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.5767\n",
            "Epoch 00024: val_loss did not improve from 3.49944\n",
            "16/16 [==============================] - 2s 138ms/step - loss: 0.5778 - val_loss: 14.0947\n",
            "Epoch 25/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.5583\n",
            "Epoch 00025: val_loss did not improve from 3.49944\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.5808 - val_loss: 12.4598\n",
            "Epoch 26/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.4728\n",
            "Epoch 00026: val_loss did not improve from 3.49944\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.4934 - val_loss: 10.9511\n",
            "Epoch 27/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.4693\n",
            "Epoch 00027: val_loss did not improve from 3.49944\n",
            "16/16 [==============================] - 2s 138ms/step - loss: 0.5207 - val_loss: 10.0507\n",
            "Epoch 28/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.5023\n",
            "Epoch 00028: val_loss did not improve from 3.49944\n",
            "16/16 [==============================] - 2s 138ms/step - loss: 0.4715 - val_loss: 11.0162\n",
            "Epoch 29/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.4574\n",
            "Epoch 00029: val_loss did not improve from 3.49944\n",
            "16/16 [==============================] - 2s 138ms/step - loss: 0.4805 - val_loss: 9.3178\n",
            "Epoch 30/30\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.4678\n",
            "Epoch 00030: val_loss did not improve from 3.49944\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.4954 - val_loss: 7.8712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLn7LgjzSF9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0d0588c2-1b96-453e-c35b-49a1dfa13c0a"
      },
      "source": [
        "# tune margin\n",
        "\n",
        "lr=1e-3\n",
        "margins=[0.2,1]\n",
        "\n",
        "model_type='deep'\n",
        "classification=False\n",
        "transfer=True\n",
        "freeze_weights=False\n",
        "\n",
        "loss_type='triplet'\n",
        "l2_normalize=1 if loss_type=='triplet' else 0\n",
        "\n",
        "model_dir=os.path.join(dataset_dir,model_type)\n",
        "if not os.path.isdir(model_dir):\n",
        "  os.mkdir(model_dir)\n",
        "\n",
        "num_epochs=25\n",
        "\n",
        "fig,ax=plt.subplots(1,len(margins))\n",
        "ax=ax.ravel()\n",
        "for margin_index,margin in enumerate(margins):\n",
        "\n",
        "  model=construct_model(model_type,input_dim,classification,num_classes,transfer,freeze_weights,l2_normalize)\n",
        "  loss=construct_loss(loss_type,margin)\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(lr),loss=loss)\n",
        "\n",
        "  history = model.fit(\n",
        "      train_dataset,\n",
        "      epochs=num_epochs)\n",
        "\n",
        "  ax[margin_index].set_title('Loss for margin_%s'%(str(margin)))\n",
        "  ax[margin_index].plot(np.arange(num_epochs),history.history['loss'],'r',label='train_loss_margin_%s'%(str(margin)))\n",
        "  \n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(model_dir,'loss_plot_margin_%s_transfer_%s_freeze_%s_%s_%s.png'%(model_type,transfer,freeze_weights,loss_type,margin)))\n",
        "plt.close()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "16/16 [==============================] - 10s 650ms/step - loss: 0.1618\n",
            "Epoch 2/25\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.1519\n",
            "Epoch 3/25\n",
            "16/16 [==============================] - 2s 127ms/step - loss: 0.1404\n",
            "Epoch 4/25\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.1343\n",
            "Epoch 5/25\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.1330\n",
            "Epoch 6/25\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.1303\n",
            "Epoch 7/25\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.1263\n",
            "Epoch 8/25\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.1279\n",
            "Epoch 9/25\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.1290\n",
            "Epoch 10/25\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.1274\n",
            "Epoch 11/25\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.1227\n",
            "Epoch 12/25\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.1183\n",
            "Epoch 13/25\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 0.1209\n",
            "Epoch 14/25\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.1200\n",
            "Epoch 15/25\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.1228\n",
            "Epoch 16/25\n",
            "16/16 [==============================] - 2s 127ms/step - loss: 0.1162\n",
            "Epoch 17/25\n",
            "16/16 [==============================] - 2s 127ms/step - loss: 0.1152\n",
            "Epoch 18/25\n",
            "16/16 [==============================] - 2s 127ms/step - loss: 0.1146\n",
            "Epoch 19/25\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.1107\n",
            "Epoch 20/25\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.1156\n",
            "Epoch 21/25\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.1164\n",
            "Epoch 22/25\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.1087\n",
            "Epoch 23/25\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.1117\n",
            "Epoch 24/25\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.1084\n",
            "Epoch 25/25\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.1135\n",
            "Epoch 1/25\n",
            "16/16 [==============================] - 9s 579ms/step - loss: 0.9480\n",
            "Epoch 2/25\n",
            "16/16 [==============================] - 2s 115ms/step - loss: 0.9404\n",
            "Epoch 3/25\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.9229\n",
            "Epoch 4/25\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.9208\n",
            "Epoch 5/25\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.9208\n",
            "Epoch 6/25\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.9198\n",
            "Epoch 7/25\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.9170\n",
            "Epoch 8/25\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.9177\n",
            "Epoch 9/25\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.9113\n",
            "Epoch 10/25\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.9303\n",
            "Epoch 11/25\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.9271\n",
            "Epoch 12/25\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.9156\n",
            "Epoch 13/25\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.9046\n",
            "Epoch 14/25\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.9182\n",
            "Epoch 15/25\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.9131\n",
            "Epoch 16/25\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.9252\n",
            "Epoch 17/25\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.9126\n",
            "Epoch 18/25\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.9178\n",
            "Epoch 19/25\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.9176\n",
            "Epoch 20/25\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.9026\n",
            "Epoch 21/25\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.9089\n",
            "Epoch 22/25\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.9077\n",
            "Epoch 23/25\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.9032\n",
            "Epoch 24/25\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.9000\n",
            "Epoch 25/25\n",
            "16/16 [==============================] - 2s 117ms/step - loss: 0.9088\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}