{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_vgg.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slala2121/Triplet-net-keras/blob/COS597D/cifar10_vgg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te4p4u4qanet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# source: https://github.com/geifmany/cifar-vgg/blob/master/cifar10vgg.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkoxKjDZaFxv",
        "colab_type": "code",
        "outputId": "4984687e-31e1-4e3d-d292-cdaeff7a2b76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install --upgrade tensorflow\n",
        "!pip install tensorflow-addons"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 51kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 38.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 42.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/f8/84b5771faec3eba9fe0c91c8c5896364a8ba08852c0dea5ad2025026dd95/google_auth-1.10.0-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (42.0.2)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.2.7)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.0)\n",
            "\u001b[31mERROR: tensorboard 2.0.2 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.10.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, google-auth, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed google-auth-1.10.0 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/b0/6a1dacc2f4fab422926bfcbab6fa8f08f2a0309d872f3b059340a409b194/tensorflow_addons-0.6.0-cp36-cp36m-manylinux2010_x86_64.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 6.6MB/s \n",
            "\u001b[?25hCollecting tensorflow-gpu==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n",
            "\u001b[K     |████████████████████████████████| 380.8MB 44kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons) (1.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (2.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (2.0.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.11.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (3.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.33.6)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.2.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.17.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0->tensorflow-addons) (0.1.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0->tensorflow-addons) (42.0.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (1.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (3.1.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (2.21.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0->tensorflow-addons) (2.8.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (4.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (0.2.7)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (4.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow-addons) (0.4.8)\n",
            "Installing collected packages: tensorflow-gpu, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.6.0 tensorflow-gpu-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5DImshPaJY2",
        "colab_type": "code",
        "outputId": "42384b6e-5f9d-4989-80f0-826c22e895a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzte3S0noxqB",
        "colab_type": "code",
        "outputId": "891da434-9259-45d8-b393-25f1dc331848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# current work around for fixing the lifted structure loss file\n",
        "\n",
        "%%writefile /usr/local/lib/python3.6/dist-packages/tensorflow_addons/losses/lifted.py\n",
        "\n",
        "\n",
        "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Implements lifted_struct_loss.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow_addons.losses import metric_learning\n",
        "from tensorflow_addons.utils import keras_utils\n",
        "\n",
        "\n",
        "@keras_utils.register_keras_custom_object\n",
        "@tf.function\n",
        "def lifted_struct_loss(labels, embeddings, margin=1.0):\n",
        "    \"\"\"Computes the lifted structured loss.\n",
        "\n",
        "    Args:\n",
        "      labels: 1-D tf.int32 `Tensor` with shape [batch_size] of\n",
        "        multiclass integer labels.\n",
        "      embeddings: 2-D float `Tensor` of embedding vectors. Embeddings should\n",
        "        not be l2 normalized.\n",
        "      margin: Float, margin term in the loss definition.\n",
        "\n",
        "    Returns:\n",
        "      lifted_loss: tf.float32 scalar.\n",
        "    \"\"\"\n",
        "    # Reshape [batch_size] label tensor to a [batch_size, 1] label tensor.\n",
        "    lshape = tf.shape(labels)\n",
        "    # assert lshape.shape == 1\n",
        "    labels = tf.reshape(labels, [lshape[0], 1])\n",
        "\n",
        "    # Build pairwise squared distance matrix.\n",
        "    pairwise_distances = metric_learning.pairwise_distance(embeddings)\n",
        "\n",
        "    # Build pairwise binary adjacency matrix.\n",
        "    adjacency = tf.math.equal(labels, tf.transpose(labels))\n",
        "    # Invert so we can select negatives only.\n",
        "    adjacency_not = tf.math.logical_not(adjacency)\n",
        "\n",
        "    batch_size = tf.size(labels)\n",
        "\n",
        "    diff = margin - pairwise_distances\n",
        "    mask = tf.cast(adjacency_not, dtype=tf.dtypes.float32)\n",
        "    # Safe maximum: Temporarily shift negative distances\n",
        "    #   above zero before taking max.\n",
        "    #     this is to take the max only among negatives.\n",
        "    row_minimums = tf.math.reduce_min(diff, 1, keepdims=True)\n",
        "    row_negative_maximums = tf.math.reduce_max(\n",
        "        tf.math.multiply(diff - row_minimums, mask), 1,\n",
        "        keepdims=True) + row_minimums\n",
        "\n",
        "    # Compute the loss.\n",
        "    # Keep track of matrix of maximums where M_ij = max(m_i, m_j)\n",
        "    #   where m_i is the max of alpha - negative D_i's.\n",
        "    # This matches the Caffe loss layer implementation at:\n",
        "    #   https://github.com/rksltnl/Caffe-Deep-Metric-Learning-CVPR16/blob/0efd7544a9846f58df923c8b992198ba5c355454/src/caffe/layers/lifted_struct_similarity_softmax_layer.cpp  # pylint: disable=line-too-long\n",
        "\n",
        "    max_elements = tf.math.maximum(row_negative_maximums,\n",
        "                                   tf.transpose(row_negative_maximums))\n",
        "    diff_tiled = tf.tile(diff, [batch_size, 1])\n",
        "    mask_tiled = tf.tile(mask, [batch_size, 1])\n",
        "    max_elements_vect = tf.reshape(tf.transpose(max_elements), [-1, 1])\n",
        "\n",
        "    loss_exp_left = tf.reshape(\n",
        "        tf.math.reduce_sum(\n",
        "            tf.math.multiply(\n",
        "                tf.math.exp(diff_tiled - max_elements_vect), mask_tiled),\n",
        "            1,\n",
        "            keepdims=True), [batch_size, batch_size])\n",
        "\n",
        "    loss_mat = max_elements + tf.math.log(loss_exp_left +\n",
        "                                          tf.transpose(loss_exp_left))\n",
        "    # Add the positive distance.\n",
        "    loss_mat += pairwise_distances\n",
        "\n",
        "    mask_positives = tf.cast(\n",
        "        adjacency, dtype=tf.dtypes.float32) - tf.linalg.diag(\n",
        "            tf.ones([batch_size]))\n",
        "\n",
        "    # *0.5 for upper triangular, and another *0.5 for 1/2 factor for loss^2.\n",
        "    num_positives = tf.math.reduce_sum(mask_positives) / 2.0\n",
        "\n",
        "    lifted_loss = tf.math.truediv(\n",
        "        0.25 * tf.math.reduce_sum(\n",
        "            tf.math.square(\n",
        "                tf.math.maximum(\n",
        "                    tf.math.multiply(loss_mat, mask_positives), 0.0))),\n",
        "        num_positives)\n",
        "    return lifted_loss\n",
        "\n",
        "\n",
        "@keras_utils.register_keras_custom_object\n",
        "class LiftedStructLoss(tf.keras.losses.Loss):\n",
        "    \"\"\"Computes the lifted structured loss.\n",
        "\n",
        "    The loss encourages the positive distances (between a pair of embeddings\n",
        "    with the same labels) to be smaller than any negative distances (between\n",
        "    a pair of embeddings with different labels) in the mini-batch in a way\n",
        "    that is differentiable with respect to the embedding vectors.\n",
        "    See: https://arxiv.org/abs/1511.06452.\n",
        "\n",
        "    Args:\n",
        "      margin: Float, margin term in the loss definition.\n",
        "      name: Optional name for the op.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, margin=1.0, name=None):\n",
        "        super(LiftedStructLoss, self).__init__(\n",
        "            name=name, reduction=tf.keras.losses.Reduction.NONE)\n",
        "        self.margin = margin\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        return lifted_struct_loss(y_true, y_pred, self.margin)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            \"margin\": self.margin,\n",
        "        }\n",
        "        base_config = super(LiftedStructLoss, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /usr/local/lib/python3.6/dist-packages/tensorflow_addons/losses/lifted.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0aQO4QBoyfT",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdklMKHYoy-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20iBXCg3euDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "import tensorflow.keras.layers\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "import numpy as np\n",
        "import os\n",
        "# from tensorflow.keras.layers.core import Lambda\n",
        "# from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow_addons as tfa\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# os.chdir('drive/My Drive')\n",
        "results_path=os.path.join('.','Colab Notebooks','cifar10')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2q_GlLwZ8So",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class cifar10vgg:\n",
        "\n",
        "    # loss_type: triplet/lifted/entropy\n",
        "    # model_type: shallow, vgg\n",
        "    def __init__(self,debug=False,loss_type='entropy',model_type='shallow',transfer_weights=False,model_path='',load_weights=False,tune_lr=False):\n",
        "        self.num_classes = 10\n",
        "        self.weight_decay = 0.0005\n",
        "        self.x_shape = [32,32,3]\n",
        "\n",
        "        self.debug=debug\n",
        "        self.tune_lr=tune_lr\n",
        "        self.loss_type = loss_type\n",
        "        self.model_type=model_type\n",
        "        self.transfer_weights=transfer_weights\n",
        "        self.model_path=model_path\n",
        "\n",
        "        self.model = self.build_model_transfer() if transfer_weights else self.build_model()        \n",
        "        self.loss_fn=self.construct_loss()\n",
        "\n",
        "        if load_weights:\n",
        "          self.model.load_weights(model_path)\n",
        "\n",
        "    def build_model_transfer(self):\n",
        "      # only support for the vgg\n",
        "      base_model=self.build_complete_vgg_model()\n",
        "      base_model.load_weights(self.model_path)\n",
        "      \n",
        "\n",
        "      if self.loss_type != 'entropy':\n",
        "        base_model.pop()\n",
        "        base_model.pop()\n",
        "\n",
        "      if self.loss_type=='triplet':\n",
        "        base_model.add(tf.keras.layers.Lambda(lambda y: tf.math.l2_normalize(y, axis=1)))\n",
        "\n",
        "      return base_model\n",
        "    \n",
        "\n",
        "    def build_model(self):\n",
        "      if self.model_type=='shallow':\n",
        "        model=self.build_shallow_model()\n",
        "      elif self.model_type=='vgg':\n",
        "        model=self.build_vgg_model()\n",
        "\n",
        "      if self.loss_type=='triplet':\n",
        "        model.add(tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)))\n",
        "\n",
        "      return model\n",
        "\n",
        "    # inspired by triplet paper\n",
        "    def build_shallow_model(self):\n",
        "      model=tf.keras.Sequential()\n",
        "      model.add(tf.keras.layers.Input(self.x_shape))\n",
        "\n",
        "      model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=5, padding='same', activation='relu'))\n",
        "      model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "      model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "      model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "      model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "      model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "      model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'))\n",
        "      model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "      model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "      model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=2, padding='same',activation='relu'))\n",
        "      model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "      # added this extraa FC layer to match vgg architecture\n",
        "      model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "      model.add(tf.keras.layers.BatchNormalization())\n",
        "      model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "      # this addition needs to be tweaked but is based on the vgg\n",
        "      if loss_type=='entropy':\n",
        "        model.add(tf.keras.layers.Dense(self.num_classes,activation='softmax'))\n",
        "      \n",
        "      return model\n",
        "\n",
        "    def build_vgg_model(self):\n",
        "        # Build the network of vgg for 10 classes with massive dropout and weight decay as described in the paper.\n",
        "\n",
        "        model = Sequential()\n",
        "        weight_decay = self.weight_decay\n",
        "\n",
        "        model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                         input_shape=self.x_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.3))\n",
        "\n",
        "        model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        if self.loss_type=='entropy':\n",
        "          model.add(Dense(self.num_classes))\n",
        "          model.add(Activation('softmax'))\n",
        "        # else:\n",
        "        #   model.add(Dense(256,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        #   model.add(Activation('relu'))\n",
        "        #   model.add(Dropout(0.5))\n",
        "\n",
        "        return model\n",
        "\n",
        "    def build_complete_vgg_model(self):\n",
        "        # Build the network of vgg for 10 classes with massive dropout and weight decay as described in the paper.\n",
        "\n",
        "        model = Sequential()\n",
        "        \n",
        "        weight_decay = self.weight_decay\n",
        "\n",
        "        model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                        input_shape=self.x_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.3))\n",
        "\n",
        "        model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(self.num_classes))\n",
        "        model.add(Activation('softmax'))\n",
        "        return model\n",
        "\n",
        "    def normalize(self,X_train,X_test):\n",
        "        #this function normalize inputs for zero mean and unit variance\n",
        "        # it is used when training a model.\n",
        "        # Input: training set and test set\n",
        "        # Output: normalized training set and test set according to the trianing set statistics.\n",
        "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
        "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
        "        X_train = (X_train-mean)/(std+1e-7)\n",
        "        X_test = (X_test-mean)/(std+1e-7)\n",
        "        return X_train, X_test\n",
        "\n",
        "    def normalize_production(self,x):\n",
        "        #this function is used to normalize instances in production according to saved training set statistics\n",
        "        # Input: X - a training set\n",
        "        # Output X - a normalized training set according to normalization constants.\n",
        "\n",
        "        #these values produced during first training and are general for the standard cifar10 training set normalization\n",
        "        mean = 120.707\n",
        "        std = 64.15\n",
        "        return (x-mean)/(std+1e-7)\n",
        "\n",
        "    def predict(self,x,normalize=True,batch_size=50):\n",
        "        if normalize:\n",
        "            x = self.normalize_production(x)\n",
        "        return self.model.predict(x,batch_size)\n",
        "\n",
        "\n",
        "    def construct_loss(self):\n",
        "      if loss_type=='triplet':\n",
        "        loss=tfa.losses.TripletSemiHardLoss(margin=1.0)\n",
        "      elif loss_type=='lifted':\n",
        "        loss=tfa.losses.LiftedStructLoss(margin=1.0)\n",
        "      elif loss_type=='entropy':\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "      return loss\n",
        "\n",
        "    def train(self,model,learning_rate):\n",
        "\n",
        "        #training parameters\n",
        "        batch_size = 128\n",
        "        maxepoches = 250\n",
        "        # learning_rate = 0.1\n",
        "        lr_decay = 1e-6\n",
        "        lr_drop = 20\n",
        "\n",
        "\n",
        "        # The data, shuffled and split between train and test sets:\n",
        "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "        x_train = x_train.astype('float32')\n",
        "        x_test = x_test.astype('float32')\n",
        "        x_train, x_test = self.normalize(x_train, x_test)\n",
        "\n",
        "        if self.loss_type=='entropy':\n",
        "          y_train = keras.utils.to_categorical(y_train, self.num_classes)\n",
        "          y_test = keras.utils.to_categorical(y_test, self.num_classes)\n",
        "\n",
        "\n",
        "        if self.tune_lr:\n",
        "          batch_size=10\n",
        "          maxepoches=20\n",
        "\n",
        "          x_train=x_train[0:100]\n",
        "          y_train=y_train[0:100]\n",
        "\n",
        "          x_test=x_test[0:100]\n",
        "          y_test=y_test[0:100]\n",
        "\n",
        "        if self.debug:\n",
        "          batch_size=10\n",
        "          maxepoches=2\n",
        "\n",
        "          x_train=x_train[0:10]\n",
        "          y_train=y_train[0:10]\n",
        "\n",
        "          x_test=x_test[0:10]\n",
        "          y_test=y_test[0:10]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        def lr_scheduler(epoch):\n",
        "            return learning_rate * (0.5 ** (epoch // lr_drop))\n",
        "        reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "        #data augmentation\n",
        "        datagen = ImageDataGenerator(\n",
        "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "            samplewise_center=False,  # set each sample mean to 0\n",
        "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "            samplewise_std_normalization=False,  # divide each input by its std\n",
        "            zca_whitening=False,  # apply ZCA whitening\n",
        "            rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "            horizontal_flip=True,  # randomly flip images\n",
        "            vertical_flip=False)  # randomly flip images\n",
        "        # (std, mean, and principal components if ZCA whitening is applied).\n",
        "        datagen.fit(x_train)\n",
        "\n",
        "        #optimization details\n",
        "\n",
        "        sgd = optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
        "        model.compile(loss=self.loss_fn, optimizer=sgd,metrics=['accuracy'])\n",
        "\n",
        "        # Prepare model model saving directory.\n",
        "        if self.tune_lr:\n",
        "          # training process in a for loop with learning rate drop every 25 epoches.\n",
        "          historytemp = model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                          batch_size=batch_size),\n",
        "                              steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                              epochs=maxepoches,verbose=0)\n",
        "          losses=np.array([historytemp.history['loss']])\n",
        "\n",
        "        else:\n",
        "          save_dir = os.path.join(results_path, '%s_%s_%s_%s_saved_models'%(self.loss_type,self.model_type,self.transfer_weights,str(learning_rate)))\n",
        "          model_name = 'cifar10_vgg_best_model.h5'\n",
        "          if not os.path.isdir(save_dir):\n",
        "              os.makedirs(save_dir)\n",
        "          filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "          # Prepare callbacks for model saving and for learning rate adjustment.\n",
        "          checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                                      monitor='val_loss',\n",
        "                                      verbose=1,\n",
        "                                      save_best_only=True)\n",
        "\n",
        "          # training process in a for loop with learning rate drop every 25 epoches.\n",
        "\n",
        "          historytemp = model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                          batch_size=batch_size),\n",
        "                              steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                              epochs=maxepoches,\n",
        "                              validation_data=(x_test, y_test),callbacks=[reduce_lr,checkpoint],verbose=2)\n",
        "          model.save_weights(os.path.join(save_dir,'cifar10_vgg_final_model.h5'))\n",
        "\n",
        "          losses=np.array([historytemp.history['loss'], historytemp.history['val_loss']])\n",
        "          np.save(os.path.join(save_dir,'loss.npy'),losses)\n",
        "          plt.figure()\n",
        "          plt.plot(historytemp.history['loss'],'r',label='train')\n",
        "          plt.plot(historytemp.history['val_loss'],'b',label='test')\n",
        "          plt.legend()\n",
        "          plt.savefig(os.path.join(save_dir,'loss.png'))\n",
        "          plt.close()\n",
        "\n",
        "\n",
        "        return model, losses\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL5mH545aez3",
        "colab_type": "code",
        "outputId": "1f162f1e-6608-43fc-a940-d6bada8853a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "model_path=os.path.join('.','Colab Notebooks','cifar10','cifar10vgg_pretrained.h5') # path for fine tuning the model\n",
        "\n",
        "debug=False\n",
        "tune_lr=True\n",
        "loss_type='lifted'\n",
        "model_type='vgg'\n",
        "transfer_weights=True\n",
        "load_weights=False\n",
        "\n",
        "lrs=[1e-1,1e-2,1e-3,1e-4,1e-5,1e-6]\n",
        "fig,ax=plt.subplots(2,3)\n",
        "ax=ax.ravel()\n",
        "for lr_index,lr in enumerate(lrs):\n",
        "  print(\"lr \", lr)\n",
        "  # model config\n",
        "  \n",
        "  model_helper = cifar10vgg(debug,loss_type,model_type,transfer_weights,model_path,load_weights,tune_lr)\n",
        "\n",
        "  # train/evaluate\n",
        "  trained_model, losses = model_helper.train(model_helper.model,lr)\n",
        "  ax[lr_index].plot(np.arange(len(losses[0])),losses[0])\n",
        "  ax[lr_index].set_title('LR = %s' %(str(lr)))\n",
        "\n",
        "save_path=os.path.join(results_path,'%s_%s_%s_tune_lr.png'%(loss_type,model_type,transfer_weights))\n",
        "plt.savefig(save_path)"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function pairwise_distance at 0x7f7e64d1ed08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function pairwise_distance at 0x7f7e64d1ed08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noZhD/B9vQr6LeW6TnwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTmUWcnKpuW-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "de1f4109-670e-415c-cb39-9db363d6b8b6"
      },
      "source": [
        "pretrained_model_path=os.path.join('.','Colab Notebooks','cifar10','cifar10vgg_pretrained.h5') # path for fine tuning the model\n",
        "\n",
        "# model config\n",
        "debug=False\n",
        "tune_lr=False\n",
        "loss_type='triplet'\n",
        "model_type='vgg'\n",
        "transfer_weights=True\n",
        "init_learning_rate=1e-3\n",
        "load_weights=False\n",
        "model_helper = cifar10vgg(debug,loss_type,model_type,transfer_weights,model_path,load_weights,tune_lr)\n",
        "\n",
        "# train/evaluate\n",
        "trained_model, losses = model_helper.train(model_helper.model,init_learning_rate)"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-206-3a2d32793ebd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# train/evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit_learning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-204-ad6463dc03b0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, learning_rate)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_type\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'entropy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-204-ad6463dc03b0>\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(self, X_train, X_test)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;31m# Output: normalized training set and test set according to the trianing set statistics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstd\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mstd\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m   3379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3380\u001b[0m     return _methods._std(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[0;32m-> 3381\u001b[0;31m                          **kwargs)\n\u001b[0m\u001b[1;32m   3382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_std\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[0;32m--> 217\u001b[0;31m                keepdims=keepdims)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# Note that x may not be inexact and that we need it to be an array,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;31m# not a scalar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0marrmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVIS5zazmHjb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "679027ee-3525-44d7-b40a-369650059f9b"
      },
      "source": [
        "\n",
        "# load trained model settings and evaluate\n",
        "debug=True\n",
        "loss_type='triplet'\n",
        "model_type='shallow'\n",
        "transfer_weights=False\n",
        "init_learning_rate=0.1\n",
        "load_weights=True\n",
        "\n",
        "model_path=os.path.join('.','Colab Notebooks','cifar10','%s_%s_%s_%s_saved_models'%(loss_type,model_type,transfer_weights,str(init_learning_rate)))\n",
        "model_file_path=os.path.join(model_path,'cifar10_vgg_best_model.h5')\n",
        "\n",
        "new_model_helper = cifar10vgg(debug,loss_type,model_type,transfer_weights,model_file_path,load_weights)\n",
        "\n",
        "(X_train,y_train),(X_test,y_test)=cifar10.load_data()\n",
        "mean = np.mean(X_train,axis=(0,1,2,3))\n",
        "std = np.std(X_train, axis=(0, 1, 2, 3))\n",
        "X_train = (X_train-mean)/(std+1e-7)\n",
        "X_test = (X_test-mean)/(std+1e-7)\n",
        "\n",
        "if debug:\n",
        "  X_test=X_test[0:10]\n",
        "  y_test=y_test[0:10]\n",
        "\n",
        "y_test_preds=new_model_helper.model.predict(X_test)\n",
        "y_test_preds_labels=np.argmax(y_test_preds,axis=1)\n",
        "\n",
        "\n",
        "print(np.sum(y_test_preds_labels==y_test[:,0])/len(y_test)*1.0)\n"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA4MNClQRgjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# performance measures\n",
        "\n",
        "# evaluate performance of model using Recall@K\n",
        "\n",
        "# retrieve k nearest neighbors based on embeddings\n",
        "\n",
        "\n",
        "# pairwise distance matrix computation: \n",
        "# https://stackoverflow.com/questions/37009647/compute-pairwise-distance-in-a-batch-without-replicating-tensor-in-tensorflow\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def forward(A):\n",
        "  r = tf.reduce_sum(A*A, 1)\n",
        "  r = tf.reshape(r, [-1, 1])\n",
        "  D = r - 2*tf.matmul(A, tf.transpose(A)) + tf.transpose(r)\n",
        "  return D\n",
        "# A = tf.constant([[1, 1], [2, 2], [3, 3]])\n",
        "# res=forward(A)\n",
        "# print(res)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "D: 2d array num_samplesxnum_samples (num_samples >=2)\n",
        "test_labels: 1d array num_samples\n",
        "k: int # nearest neighbors >=1\n",
        "\"\"\"\n",
        "def compute_recall_at_k(Dist_matrix,test_labels,k):\n",
        "  num_samples=Dist_matrix.shape[0]\n",
        "  recall=0\n",
        "  for sample_index in range(num_samples):\n",
        "    ind_samples_sorted_by_distance=np.argsort(Dist_matrix[sample_index])\n",
        "    # assert ind_samples_sorted_by_distance[0]==sample_index\n",
        "    ind_samples_sorted_by_distance=ind_samples_sorted_by_distance[1:]# exclude the sample in question\n",
        "    \n",
        "    ind_nearest_k_neighbors=ind_samples_sorted_by_distance[:k]\n",
        "    labels_nearest_k_neighbors=test_labels[ind_nearest_k_neighbors]\n",
        "    true_label=test_labels[sample_index]\n",
        "\n",
        "    if true_label in labels_nearest_k_neighbors:\n",
        "      recall+=1\n",
        "\n",
        "  recall*=(1.0/num_samples)\n",
        "\n",
        "  return recall\n",
        "\n",
        "\n",
        "# test compute_recall_at_k\n",
        "\n",
        "# recall = 1, recall < 1\n",
        "from sklearn.datasets import make_spd_matrix\n",
        "np.random.seed(15)\n",
        "num_samples=6\n",
        "D=make_spd_matrix(num_samples)\n",
        "D=np.abs(D)\n",
        "for i in range(num_samples):\n",
        "  D[i,i]=0\n",
        "\n",
        "test_labels=np.random.randint(0,3,size=num_samples)\n",
        "test_labels[-1]=1\n",
        "\n",
        "recall_score=compute_recall_at_k(D,test_labels,k=num_samples)\n",
        "assert np.allclose(recall_score,1.0)\n",
        "\n",
        "recall_score=compute_recall_at_k(D,test_labels,k=1)\n",
        "assert np.allclose(recall_score,1./6)\n",
        "\n",
        "recall_score=compute_recall_at_k(D,test_labels,k=2)\n",
        "assert np.allclose(recall_score,2./3)\n",
        "\n",
        "recall_score=compute_recall_at_k(D,test_labels,k=3)\n",
        "assert np.allclose(recall_score,2./3)\n",
        "\n",
        "recall_score=compute_recall_at_k(D,test_labels,k=4)\n",
        "assert np.allclose(recall_score,1.0)\n",
        "\n",
        "recall_score=compute_recall_at_k(D,test_labels,k=5)\n",
        "assert np.allclose(recall_score,1.0)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8KPP8gQji1s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "3e649121-970c-4d4f-d96c-f728a963892d"
      },
      "source": [
        "new_model_helper.model.summary()"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_91\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_761 (Conv2D)          (None, 32, 32, 64)        4864      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_357 (MaxPoolin (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_631 (Dropout)        (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_762 (Conv2D)          (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_358 (MaxPoolin (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_632 (Dropout)        (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_763 (Conv2D)          (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_359 (MaxPoolin (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_633 (Dropout)        (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_764 (Conv2D)          (None, 4, 4, 128)         131200    \n",
            "_________________________________________________________________\n",
            "flatten_89 (Flatten)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_173 (Dense)            (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_669 (Bat (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_634 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "lambda_9 (Lambda)            (None, 128)               0         \n",
            "=================================================================\n",
            "Total params: 767,872\n",
            "Trainable params: 767,616\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5a0mQl_jOKJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "db4f31e1-e5bf-431e-a268-be284ddfc6e3"
      },
      "source": [
        "# choose an embedding layer to evaluate\n",
        "\n",
        "embed_layer_index=-1\n",
        "embeddings_layer_model=tf.keras.models.Model(inputs=new_model_helper.model.input,outputs=new_model_helper.model.layers[embed_layer_index].output)\n",
        "\n",
        "# evaluate performance\n",
        "\n",
        "# smaller_test_dataset=test_dataset.take(num_batches_to_take)\n",
        "smaller_test_dataset=X_test\n",
        "test_labels=y_test\n",
        "\n",
        "# embeddings_layer_model=models\n",
        "predictions=embeddings_layer_model.predict(smaller_test_dataset)\n",
        "\n",
        "# computes pairwise distance between the rows of predictions\n",
        "D=forward(predictions)\n",
        "\n",
        "import time\n",
        "Ks=[1,2,5,10]\n",
        "recall_by_k=[]\n",
        "for k in Ks:\n",
        "  t_start=time.time()\n",
        "  recall_at_k=compute_recall_at_k(D,test_labels,k)\n",
        "  t_end=time.time()\n",
        "  print(\"computing takes \", (t_end-t_start)*1.0/60) \n",
        "  recall_by_k.append(recall_at_k)\n",
        "recall_by_k=np.array(recall_by_k)\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(Ks,recall_by_k,color='r',marker='o')\n",
        "plt.ylabel('Recall@K score (%)')\n",
        "plt.xlabel('K')\n",
        "plt.title('Recall@K score for %s_%s_%s model finetuned on Cifar10' %(loss_type,model_type,transfer_weights))\n",
        "plt.savefig(os.path.join(model_path,'recall_by_k.png'))\n",
        "\n",
        "np.save(os.path.join(model_path,'recall_by_k_.npy'),recall_by_k)"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "computing takes  8.077621459960938e-05\n",
            "computing takes  8.400281270345052e-05\n",
            "computing takes  8.459885915120442e-05\n",
            "computing takes  8.366902669270833e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAEWCAYAAADcsGj7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEjJUkiJiEjJUkiJiEjJ+n+qOwBzxZZrvAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI1KOHiloaiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}